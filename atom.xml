<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>看见什么吃什么</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zjsnowman.com/"/>
  <updated>2020-01-08T09:50:45.874Z</updated>
  <id>http://zjsnowman.com/</id>
  
  <author>
    <name>张俊</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>吴亦凡微博流量分析</title>
    <link href="http://zjsnowman.com/2020/01/08/%E5%90%B4%E4%BA%A6%E5%87%A1%E5%BE%AE%E5%8D%9A%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/"/>
    <id>http://zjsnowman.com/2020/01/08/%E5%90%B4%E4%BA%A6%E5%87%A1%E5%BE%AE%E5%8D%9A%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/</id>
    <published>2020-01-08T09:48:34.000Z</published>
    <updated>2020-01-08T09:50:45.874Z</updated>
    
    <content type="html"><![CDATA[<p>吴亦凡的微博分析<a id="more"></a></p><p><div class="tableauPlaceholder" id="viz1578476930282" style="position: relative"><noscript><a href="#"><img alt=" " src="https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;16&#47;16156&#47;1&#47;1_rss.png" style="border: none"></a></noscript><object class="tableauViz" style="display:none;"><param name="host_url" value="https%3A%2F%2Fpublic.tableau.com%2F"> <param name="embed_code_version" value="3"> <param name="site_root" value><param name="name" value="16156&#47;1"><param name="tabs" value="no"><param name="toolbar" value="yes"><param name="static_image" value="https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;16&#47;16156&#47;1&#47;1.png"> <param name="animate_transition" value="yes"><param name="display_static_image" value="yes"><param name="display_spinner" value="yes"><param name="display_overlay" value="yes"><param name="display_count" value="yes"></object></div>                <script type="text/javascript">                    var divElement = document.getElementById('viz1578476930282');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='1016px';vizElement.style.height='991px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script></p><p>参考:<a href="https://mp.weixin.qq.com/s/Neh3asFZAtcIzywwXstBYQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Neh3asFZAtcIzywwXstBYQ</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;吴亦凡的微博分析
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>文本分析</title>
    <link href="http://zjsnowman.com/2019/12/26/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/"/>
    <id>http://zjsnowman.com/2019/12/26/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/</id>
    <published>2019-12-26T02:12:44.000Z</published>
    <updated>2019-12-30T10:57:12.752Z</updated>
    
    <content type="html"><![CDATA[<p>简单文本分析。具体包括两方面内容关键字提取，情感分析<a id="more"></a></p><h1 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h1><ul><li>分词(<code>jieba.cut</code>)</li><li>关键字提取(<code>jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())</code>)</li><li>情感分析</li></ul><h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><h2 id="词云"><a href="#词云" class="headerlink" title="词云"></a>词云</h2><ul><li>Tableau</li><li>pyechart<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_word_cloud</span><span class="params">(data, swords)</span>:</span></span><br><span class="line">    text = <span class="string">''</span>.join(data[<span class="string">'content'</span>])</span><br><span class="line">    words = list(jieba.cut(text))</span><br><span class="line">    ex_sw_words = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">if</span> len(word)&gt;<span class="number">1</span> <span class="keyword">and</span> (word <span class="keyword">not</span> <span class="keyword">in</span> swords):</span><br><span class="line">            ex_sw_words.append(word)</span><br><span class="line">    c = Counter()</span><br><span class="line">    c = Counter(ex_sw_words)</span><br><span class="line">    wc_data = pd.DataFrame(&#123;<span class="string">'word'</span>:list(c.keys()), <span class="string">'counts'</span>:list(c.values())&#125;).sort_values(by=<span class="string">'counts'</span>, ascending=<span class="literal">False</span>).head(<span class="number">100</span>)</span><br><span class="line">    wordcloud = WordCloud()</span><br><span class="line">    wordcloud.add(<span class="string">""</span>, wc_data.values.tolist(), word_size_range=[<span class="number">20</span>, <span class="number">100</span>])</span><br><span class="line">    <span class="keyword">return</span> wordcloud</span><br><span class="line">    </span><br><span class="line">plot_word_cloud(data=data[data[<span class="string">'score'</span>]&gt;<span class="number">6</span>], swords=swords).render_notebook()</span><br></pre></td></tr></table></figure></li></ul><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://www.ruanyifeng.com/blog/2013/03/tf-idf.html" target="_blank" rel="noopener">TF-IDF应用</a></li><li><a href="https://pyecharts.org/#/zh-cn/quickstart" target="_blank" rel="noopener">pyechart 快速上手</a></li><li><a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">jieba分词</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简单文本分析。具体包括两方面内容关键字提取，情感分析
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>精力管理</title>
    <link href="http://zjsnowman.com/2019/02/25/%E7%B2%BE%E5%8A%9B%E7%AE%A1%E7%90%86/"/>
    <id>http://zjsnowman.com/2019/02/25/%E7%B2%BE%E5%8A%9B%E7%AE%A1%E7%90%86/</id>
    <published>2019-02-25T05:41:06.000Z</published>
    <updated>2019-10-21T02:55:51.586Z</updated>
    
    <content type="html"><![CDATA[<p>目前感觉事情越来越多了，精力不太够用，偶然机会看到协和医院医学博士张遇升的精力管理课程，觉得很受用。和大家分享，希望对各位有所启发<a id="more"></a></p><h1 id="思维导图大纲"><a href="#思维导图大纲" class="headerlink" title="思维导图大纲"></a>思维导图大纲</h1><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/blog/2019-02-25-%E7%B2%BE%E5%8A%9B%E7%AE%A1%E7%90%86.png" alt="精力管理"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前感觉事情越来越多了，精力不太够用，偶然机会看到协和医院医学博士张遇升的精力管理课程，觉得很受用。和大家分享，希望对各位有所启发
    
    </summary>
    
    
    
      <category term="others" scheme="http://zjsnowman.com/tags/others/"/>
    
  </entry>
  
  <entry>
    <title>2019 寻找潜在工作指南</title>
    <link href="http://zjsnowman.com/2019/02/19/%E7%8B%AC%E8%A7%92%E5%85%BD%E5%88%86%E6%9E%90/"/>
    <id>http://zjsnowman.com/2019/02/19/%E7%8B%AC%E8%A7%92%E5%85%BD%E5%88%86%E6%9E%90/</id>
    <published>2019-02-19T07:03:24.000Z</published>
    <updated>2019-10-21T02:55:51.585Z</updated>
    
    <content type="html"><![CDATA[<p>分析大中华区截止到2018年12月31号186家独角兽公司，在求职季但愿能够帮到你。不用怀疑，都是带交互的，鼠标到处点点<a id="more"></a></p><p><div class="tableauPlaceholder" id="viz1550560217499" style="position: relative"><noscript><a href="#"><img alt=" " src="https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Un&#47;UnicornAnalysisForWork&#47;sheet1&#47;1_rss.png" style="border: none"></a></noscript><object class="tableauViz" style="display:none;"><param name="host_url" value="https%3A%2F%2Fpublic.tableau.com%2F"> <param name="embed_code_version" value="3"> <param name="path" value="views&#47;UnicornAnalysisForWork&#47;sheet1?:embed=y&amp;:display_count=y&amp;publish=yes"> <param name="toolbar" value="no'/"><param name="showShareOptions" value="false"><param name="static_image" value="https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Un&#47;UnicornAnalysisForWork&#47;sheet1&#47;1.png"> <param name="animate_transition" value="yes"><param name="display_static_image" value="yes"><param name="display_spinner" value="yes"><param name="display_overlay" value="yes"><param name="display_count" value="yes"><param name="filter" value="publish=yes"></object></div>                <script type="text/javascript">                    var divElement = document.getElementById('viz1550560217499');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1000px';vizElement.style.height='1627px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1000px';vizElement.style.height='1627px';} else { vizElement.style.width='100%';vizElement.style.height='1177px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分析大中华区截止到2018年12月31号186家独角兽公司，在求职季但愿能够帮到你。不用怀疑，都是带交互的，鼠标到处点点
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>特征工程</title>
    <link href="http://zjsnowman.com/2018/12/22/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    <id>http://zjsnowman.com/2018/12/22/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</id>
    <published>2018-12-22T09:42:33.000Z</published>
    <updated>2019-10-21T02:55:51.584Z</updated>
    
    <content type="html"><![CDATA[<p>特征工程<a id="more"></a></p><h1 id="基本数据结构"><a href="#基本数据结构" class="headerlink" title="基本数据结构"></a>基本数据结构</h1><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/blog/2018-12-22-Paper.%E7%B4%A0%E6%8F%8F.1.png" alt="基本数据结构模型"><br>上图为特征工程需要了解的基本的数据结构模型。可以看做是一个DataFrame。</p><p>下面我们分别从横向和纵向分别来对数据做一些处理。<br>横向如果特征过多，我们就需要做一个特征选择。主要两个办法</p><ul><li>特征选择 选择一些特征出来，还是原有特征，从100个选10个。</li><li>进行降维，生成新的变量，这些新的变量彼此不相关。从100个生成新的10个变量，这10个变量是原来没有的。比如使用主成分分析和因子分析</li></ul><p>纵向来看，在多个样本的情况下，我们可以做聚类。比如K-mean。当然还有很多其他的聚类算法</p><h2 id="主成分分析和因子分析"><a href="#主成分分析和因子分析" class="headerlink" title="主成分分析和因子分析"></a>主成分分析和因子分析</h2><h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h3><ul><li><p>原始变量之间的相关程度高，降维效果就比较好，否则意义不大。所以可以先查看相关系数矩阵，看看适合做降维不</p></li><li><p>降维之前先做标准化最好，消除水平和量纲上的影响。</p></li><li><p>PCA的一个主要缺点就是不好解释，所以人们发明了因子分析，可以使结果尽可能达到易于解释且合理。</p></li></ul><h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ul><li>做完k-mean，需要做一个方差分析，来检验分的时候合理</li><li>分类如果含有分类变量，需要使用新的聚类方法，比如两步聚类法，密度聚类，谱聚类，混合高斯，这里可以查询资料</li><li>聚类如果变量太多，还需要先做特征选择，也就是将行缩短</li><li>双向聚类，就是在变量(行方向)，和样本(列方向)同时聚类，查阅资料。</li></ul><p>问题<br>多重共线性<br>降维后如何解释，这也是pca的缺点，不好解释。<br>主成分本质上就是特征向量，可以了解一下特征向量的求法，图像上就是椭圆的主轴。<br>相关系数矩阵里面有分类数据，如何处理，哑变量问题<br>如果有分类变量，需要做方差分析，需要去了解方差分析。</p><h2 id="多重共线性"><a href="#多重共线性" class="headerlink" title="多重共线性"></a>多重共线性</h2><p>多重共线性指的是回归模型中，两个或两个以上的自变量彼此相关。带来的问题是可能会对<br>结果造成混乱，对参数的系数的正负号产生影响，从而误导整个分享方向。<br>举例：<br>x1=x2<br>y~a1*x1+a2*x2<br>实际等价于:y~(a1+a2)x1<br>假设(a1+a2)=2,也就是说x1变化一个单元，y正向增加2个单元。但是共线性可能会导致a1=-1,a2=3,这样也是符合的。这样就会误导以为y和x1负相关，x2正相关。</p><p>所以特征选择还是很有必要的，如果变量之间有很强的关系。如果变量比较少，观察相关系数矩阵就可以判断，如果比较多，就需要去其他方法去判断，比如计算容忍度之类的。可以简单的去掉双胞胎变量，也可以通过一些向向前选择，逐步回归等方法进行变量选择。当然这些选择和PCA是不同的，那还是保留原有变量的，而不是生成新的变量。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;特征工程
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>读芒格《人类误判心理学》</title>
    <link href="http://zjsnowman.com/2018/12/14/%E8%AF%BB%E8%8A%92%E6%A0%BC%E3%80%8A%E4%BA%BA%E7%B1%BB%E8%AF%AF%E5%88%A4%E5%BF%83%E7%90%86%E5%AD%A6%E3%80%8B/"/>
    <id>http://zjsnowman.com/2018/12/14/%E8%AF%BB%E8%8A%92%E6%A0%BC%E3%80%8A%E4%BA%BA%E7%B1%BB%E8%AF%AF%E5%88%A4%E5%BF%83%E7%90%86%E5%AD%A6%E3%80%8B/</id>
    <published>2018-12-14T09:18:46.000Z</published>
    <updated>2019-10-21T02:55:51.587Z</updated>
    
    <content type="html"><![CDATA[<p>《人类误判心理学》金句摘抄<a id="more"></a></p><ul><li><blockquote><p>我还知道⼈人类就像被驯养的动物和猴⼦子，也⽣生 活 在⼀一种等级结构中，他倾向于尊􏰀当权者，喜欢和同阶层的成员合作，同时对处于下层 并与 之竞争的⼈人表现出极⼤大的不不信任和不不喜欢。</p></blockquote></li><li><blockquote><p>德国谚语所⾔言⾮非虚:“我们⽼老老得太快，聪明得太迟</p></blockquote></li><li><blockquote><p>蚂蚁简单的⾏行行为系统⾃自然有很⼤大的局限，因为它的神经系统的功能很有限。例例如，有⼀一种 蚂 蚁，当它在巢⽳穴⾥里里嗅到蚂蚁⼫尸体散发出的外激素时，它就会和其他蚂蚁合作把⼫尸体运出 巢⽳穴。 伟⼤大的哈佛⼤大学教授 E.O.威尔逊(E. O. Wilson)做过⼀一个⾮非常出⾊色的⼼心理理学实验， 他将死 蚂蚁分泌泌的外激素涂在⼀一只活蚂蚁身上。很⾃自然，其他蚂蚁把这只有⽤用的活蚂蚁拖 出了了巢⽳穴，尽管它在整个过程中不不断地踢腿和挣扎。这就是蚂蚁的⼤大脑。它拥有的反应程 序特别简单, 平时运转是没有问题的，但在许多情况下，蚂蚁只会⽣生搬硬套地根据这个程序 作出机械反应。</p></blockquote></li><li><blockquote><p>有些教授喜欢⽤用实验来证明对⽐比引起的感知缺陷。他们会让学⽣生把⼀一只⼿手放在⼀一桶热⽔水 ⾥里里， 另外⼀一只⼿手伸进⼀一桶冷⽔水。然后他们会突然要求学⽣生把双⼿手放进⼀一桶常温的⽔水中。学 ⽣生虽然 两只⼿手是放在同⼀一桶⽔水⾥里里⾯面，但⼀一只⼿手感觉好像刚放进冷⽔水，⼀一只⼿手感觉好像刚放 进热⽔水。 当⼈人们发现在温度计不不会出错的地⽅方，单纯的对⽐比就能轻易易地让感知受骗，并意 识到认知和感知是相同的，也会受到单纯的反差的欺骗，那么他不不但能够懂得魔术师是如 何愚弄弄⼈人们的， 还能明⽩白⽣生活是如何作弄弄⼈人的。⼈人类的感知和认知系统中那些总体上很有 ⽤用的倾向往往会出 错，如果不不对此加以⼩小⼼心提防，就会很容易易受到别⼈故意的操控。人类的——经常出错但总体上很有⽤用——⼼心理理倾向相当多，⽽而且相当不不同。⼤大量量的⼼心理理倾 向 的⾃自然结果就是社会⼼心理理学的重要原理理:认知往往取决于情景，所以不不同的情景通常会引 起不不同的结论，哪怕是同⼀一个⼈人在思考同⼀一个问题的时候也是如此。</p></blockquote></li><li><blockquote><p>富兰克林林在《穷理理查年年鉴》中说过:“如果你想 要 说服别⼈人，要诉诸利利益，⽽而⾮非诉诸理理性。”这句句睿智的箴⾔言引导⼈人们在⽣生活中掌握⼀一个􏰀 要 ⽽而简单的道理理:当你该考虑动⽤用激励机制的威⼒力力时，千万千万别考虑其他的。</p></blockquote></li><li><blockquote><p>根据斯⾦金金纳的教导，他们知道即时 的奖励是最有效的。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;《人类误判心理学》金句摘抄
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习</title>
    <link href="http://zjsnowman.com/2018/11/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/"/>
    <id>http://zjsnowman.com/2018/11/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/</id>
    <published>2018-11-27T09:20:02.000Z</published>
    <updated>2019-10-21T02:55:51.582Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/machineLearning.png" alt><br>机器学习备注<a id="more"></a></p><h1 id="Naive-Bayes-贝叶斯推断"><a href="#Naive-Bayes-贝叶斯推断" class="headerlink" title="Naive Bayes(贝叶斯推断)"></a>Naive Bayes(贝叶斯推断)</h1><p><a href="http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html" target="_blank" rel="noopener">讲解贝叶斯基本算法原理</a></p><h2 id="朴素贝叶斯为啥朴素"><a href="#朴素贝叶斯为啥朴素" class="headerlink" title="朴素贝叶斯为啥朴素"></a>朴素贝叶斯为啥朴素</h2><p>因为贝叶斯算法并没有考虑事情发生的顺序.<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fqjaoeg0euj31c00s6q87.jpg" alt></p><h2 id="朴素贝叶斯的优势和劣势"><a href="#朴素贝叶斯的优势和劣势" class="headerlink" title="朴素贝叶斯的优势和劣势"></a>朴素贝叶斯的优势和劣势</h2><ul><li>优势</li></ul><p>这种算法非常适合文本分类。在处理文本时，常见的做法是将每个单词看作一个特征，这样就会有大量的特征。此算法的相对简单性和朴素贝叶斯独立特征的这一假设，使其能够出色完成文本的分类</p><ul><li>劣势</li></ul><p>当事情的顺序很重要的时候,就不行.比如早起 google芝加哥公牛的时候.就会出现一些芝加哥的介绍或者公牛的照片.但是明显芝加哥公牛有其他的意思.这个时候贝叶斯就不是很管用的</p><ul><li>总结</li></ul><p>如何避免这些,我们采用的监督式学习.也就有试验和测试数据.通过测试就能够知道算法是否有效</p><h1 id="SVM-支持向量机"><a href="#SVM-支持向量机" class="headerlink" title="SVM(支持向量机)"></a>SVM(支持向量机)</h1><p>核心概念- 间隔(margin)  </p><ul><li>支持向量机的内部原理是最大程度提高结果稳健性</li><li>正确分类标签作为首要考虑,然后对间隔进行最大化.也就是说要在分类正确的前提下对间隔最大化</li><li>SVM 可以忽略异常值,然后使间隔最大化</li></ul><p>SVM 不适合处理海量数据,训练时间太慢了<br>噪声过多情况下,类严重重叠,边界不明显也不适合 SVM. 可以考虑用 Navie Bayes</p><p><a href="http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-33-SVM/" target="_blank" rel="noopener">参考 udacity 学习笔记</a></p><h1 id="Decision-Trees-决策树"><a href="#Decision-Trees-决策树" class="headerlink" title="Decision Trees (决策树)"></a>Decision Trees (决策树)</h1><ul><li>非参数学习方法(类似KNN 容易过拟合)</li><li>可以解决分类/回归问题</li><li>天然可以解决多分类问题</li><li>具备非常好的解释性</li></ul><h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p><a href="http://www.ruanyifeng.com/blog/2014/09/information-entropy.html" target="_blank" rel="noopener">信息熵的定义</a><br>按照信息熵减小的方向去确定分类边界</p><h2 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a>基尼系数</h2><p>类似信息熵<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-20-120435.png" alt></p><h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>容易过拟合<br>可以通过剪枝来降低模型复杂度,解决过拟合<br><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" target="_blank" rel="noopener">决策树理解,讲的不错</a><br><a href="http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-34-DecisionTrees/" target="_blank" rel="noopener">udacity 学习笔记</a></p><h1 id="k-nearest-neighbors"><a href="#k-nearest-neighbors" class="headerlink" title="k-nearest neighbors"></a>k-nearest neighbors</h1><p><a href="https://zhuanlan.zhihu.com/p/25994179" target="_blank" rel="noopener">查考</a></p><p><a href="http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-39-cluster/" target="_blank" rel="noopener">udacity学习笔记</a></p><ul><li>K近邻算法比较特殊,可以认为是没有模型的算法,为了和其他算法统一,也可以认为训练数据集就是模型本身</li></ul><h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><p><a href="http://www.cnblogs.com/pinard/p/6131423.html" target="_blank" rel="noopener">参考</a></p><ul><li>hard </li><li>soft 带权重的hard模式</li></ul><h2 id="Bagging-and-随机森林"><a href="#Bagging-and-随机森林" class="headerlink" title="Bagging and 随机森林"></a>Bagging and 随机森林</h2><p>### 如何构建不同的子模型<br>对样本和特征进行随机选择<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-25-085115.png" alt></p><p>通俗来说就是对行级别和列级别抽样,都抽样就是Patches.</p><ul><li>Bagging(样本有放回随机抽样),统计学上叫Bootstrap.不放回抽样叫Pasting</li><li>Random Subspace(特征随机抽样)  图像识别领域用的比较多,特征比较多</li><li>Random Patches (即针对样本又针对特征) ,代表就是随机深林</li></ul><h2 id="Ada-Boosting"><a href="#Ada-Boosting" class="headerlink" title="Ada Boosting"></a>Ada Boosting</h2><p>给上一个模型没有匹配到的数据更大的权值,然后重新拟合.最初的模型所有样本数据的权值是一样的<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-26-071311.png" alt></p><h2 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h2><p>对上一个模型没有匹配的样本建立一个新的模型,最后把所有模型叠加起来<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-26-071205.png" alt></p><h1 id="准确度与训练集大小的关系"><a href="#准确度与训练集大小的关系" class="headerlink" title="准确度与训练集大小的关系"></a>准确度与训练集大小的关系</h1><p>更大的数据量要比经过精密调整的算法提供更好的结果,更大的数据能够取得更好的效果,这是<br>机器学习领域至理名言</p><h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><ul><li>numberical 数值</li><li>categorical  分类</li><li>time series  时序</li><li>text  文字</li></ul><h1 id="判断离散还是连续"><a href="#判断离散还是连续" class="headerlink" title="判断离散还是连续"></a>判断离散还是连续</h1><p><strong>关注顺序</strong></p><p>有些不好判断的类型,可以关注数据之间的顺序,如果之间有强烈的关联性,则用连续性的分类器,否则就用离散性的分类器.比如,公司100个人, 工号从1-100,如果需要给他们分类,最好就用离散性的分类器,因为不同工号之前没有关联性</p><h1 id="回归-regression"><a href="#回归-regression" class="headerlink" title="回归(regression)"></a>回归(regression)</h1><h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>也叫<a href="https://www.wikiwand.com/zh-hans/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="noopener">最小平方法</a></p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>y=m*x+b 寻找系数和截距,通过最小化误差平方和</p><h3 id="线性回归误差"><a href="#线性回归误差" class="headerlink" title="线性回归误差"></a>线性回归误差</h3><p>误差=真实值-误差值 (注意存在正负值)<br><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fqjaofthnxj31kw0wmdnh.jpg" alt><br>通过上图,可以看出为啥不用误差绝对值的和而是用平方和的原因.用误差绝对值的和会存在多条线,<br>而用平方和就只会有一条</p><h3 id="误差平法和"><a href="#误差平法和" class="headerlink" title="误差平法和"></a>误差平法和</h3><p>判断拟合质量的标准</p><h4 id="最小化误差平方和的算法"><a href="#最小化误差平方和的算法" class="headerlink" title="最小化误差平方和的算法"></a>最小化误差平方和的算法</h4><ul><li>普通最小二乘法 ordinary least squares(sklearn LinearRegression中使用就是这种)</li><li>梯度下降 gradient descent</li></ul><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fqjaogtziwj31kw0sq45m.jpg" alt><br>当对不同数量的两个数据进行用最小误差平方和来评判算法好坏时会出现问题.拟合效果可能差不多,由于数量多的那个数据集天然误差平方和会大</p><h2 id="决定系数-R-suqre"><a href="#决定系数-R-suqre" class="headerlink" title="决定系数 R suqre"></a>决定系数 R suqre</h2><p><a href="https://www.wikiwand.com/zh-hans/%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0" target="_blank" rel="noopener">定义</a></p><p>决定系数的出现是为了解决上面误差平方和的缺陷.介于0-1之间,1最好,0最差.</p><h2 id="监督分类和回归的区别"><a href="#监督分类和回归的区别" class="headerlink" title="监督分类和回归的区别"></a>监督分类和回归的区别</h2><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fqjaohwj5oj31kw0vw0z3.jpg" alt></p><h2 id="多元线性回归-多变量回归-元理解成变量即可"><a href="#多元线性回归-多变量回归-元理解成变量即可" class="headerlink" title="多元线性回归(多变量回归,元理解成变量即可)"></a>多元线性回归(多变量回归,元理解成变量即可)</h2><p>多元回归和简单线性回归类似,只是变量增加而已.<br>y=x1+x2</p><h2 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h2><p>多项式回归处理方法和多元回归本质是也是一样的,只是把一元的多次作为一个特征来处理.对应<code>sklearn.preprocessing.PolynomialFeatures</code>.<br>y=x^2+x.这里把x^2 理解成一个特征即可,只是这个特征还是x这个元   .<br></p><h1 id="异常值"><a href="#异常值" class="headerlink" title="异常值"></a>异常值</h1><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><ul><li>传感器故障</li><li>数据输入错误</li></ul><h2 id="去除异常值的算法"><a href="#去除异常值的算法" class="headerlink" title="去除异常值的算法"></a>去除异常值的算法</h2><ol><li>回归</li><li>根据误差值排序,去除前10%</li><li>重新回归</li></ol><h1 id="Clustering-聚类"><a href="#Clustering-聚类" class="headerlink" title="Clustering(聚类)"></a>Clustering(聚类)</h1><h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><ol><li>将各个点分配到矩心</li><li>移动矩心,使各个点到矩心的距离最短<br>反复执行上面两个步骤<h2 id="K-means的局限"><a href="#K-means的局限" class="headerlink" title="K-means的局限"></a>K-means的局限</h2>依赖最初矩心所在的位置,不同的位置最终的结果可能会不同.<br>局部最小解</li></ol><h1 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h1><p>特征缩放的公式(x’-x_min)/(x_max-x_min)</p><h2 id="受此影响的机器学习算法"><a href="#受此影响的机器学习算法" class="headerlink" title="受此影响的机器学习算法"></a>受此影响的机器学习算法</h2><ul><li>使用 RBF 核函数的 SVM</li><li>K-means</li></ul><h1 id="涉及的一些中英对照"><a href="#涉及的一些中英对照" class="headerlink" title="涉及的一些中英对照"></a>涉及的一些中英对照</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">slope-&gt;斜率</span><br><span class="line">intercept-&gt;截距</span><br><span class="line">coefficient-&gt;系数</span><br></pre></td></tr></table></figure><h1 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h1><p>bag of words -词袋<br>stop words - 停止词<br>stemmer- 词干提取<br>TF-IDF<br>TF-Term Frequency<br>IDF-Inverse Document Frequency</p><p><a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html" target="_blank" rel="noopener">TF-IDF解释</a></p><h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>为了防止过拟合采用的一种手段,在最小化sse(误差平方和) 的同时增加惩罚措施.<br>避免采用过多的特征维度.采用维度过少会导致高偏差(high bias,误差平方和较大).采用维度过度<br>会导致高方差(high varaiance,对测试数据集拟合不佳,不具有普遍性)</p><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-09-010656.png" alt></p><ul><li>岭回归  在LinearRegression的基础上添加了L2正则项.可以理解为内置了线性模型</li></ul><p>[参考Sklearn Generaized Linear Models 这一章的前三节,具体公式也在其中.]<br>(<a href="http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression</a>)</p><h1 id="一些其他的点"><a href="#一些其他的点" class="headerlink" title="一些其他的点"></a>一些其他的点</h1><ul><li>过拟合就是在训练集上准确率非常高，而在测试集上准确率低</li></ul><h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><ul><li>一种用来降维的手段.是一种将输入特征转换为其主要特征的系统化方法</li><li>主成分的定义是数据中使方差最大话的方向(数据在上投影,使数据丢失的可能性降到最低)</li><li>主成分的上限是输入特征数量,当等于输入特征数量时就没有意义了,通常只会使用前面几个主成分</li><li>PCA最好在特征选择之前做.</li></ul><h2 id="帮助理解PCA"><a href="#帮助理解PCA" class="headerlink" title="帮助理解PCA"></a>帮助理解PCA</h2><p><a href="https://coding.imooc.com/learn/questiondetail/43110.html" target="_blank" rel="noopener">https://coding.imooc.com/learn/questiondetail/43110.html</a></p><h2 id="PCA的功能"><a href="#PCA的功能" class="headerlink" title="PCA的功能"></a>PCA的功能</h2><p>PCA可以起到降维的作用,这样主要是为了加快运行速度,另外也可以做可视化,讲数据在人类可以理解的二维或者三维上展示<br>另外一个主要的作用是降噪,在降维的同时将数据中包含的噪声减少.<br>这里需要注意的是,如果对于你的应用来说，保持特征语意很重要，又要减少特征量，是不建议使用PCA,可以试试LASSO.</p><h1 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h1><p><code>GridSearchCV</code>这个CV就是Cross Validation.<br>本质上为了更好的避免过拟合,如果没有验证数据集,训练出来的模型可能会对测试数据集过拟合.<br>所以通常将训练数据集分成训练数据集和验证数据集并配合K-Fold来对此验证取平均.这样来调模型的最佳参数.最后在用没有参与训练的测试基来检验模型的好坏</p><h1 id="方差偏差均衡"><a href="#方差偏差均衡" class="headerlink" title="方差偏差均衡"></a>方差偏差均衡</h1><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-06-092302.jpg" alt><br>通俗来说:偏差就是不准；方差就是不稳<br><a href="https://plushunter.github.io/2017/04/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8818%EF%BC%89%EF%BC%9A%E6%96%B9%E5%B7%AE%E5%81%8F%E5%B7%AE%E6%9D%83%E8%A1%A1%EF%BC%88Bias-Variance%20Tradeoff%EF%BC%89/" target="_blank" rel="noopener">参考</a></p><h1 id="如何解决过拟合问题"><a href="#如何解决过拟合问题" class="headerlink" title="如何解决过拟合问题"></a>如何解决过拟合问题</h1><ul><li><p>降低模型复杂度,比如多项式回归降低degree</p></li><li><p>正则化</p></li><li><p>增大样本数据</p></li><li><p>尝试化简，选择，提取更好的特征，所谓特征工程（特征不是越多越好！）</p></li><li><p>降噪,比如PCA</p></li><li><p>使用验证集避免针对测试数据集过拟合</p></li><li><p>尝试使用ensemble的方法（集成学习，见课程第十三章）</p></li></ul><h1 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h1><p>Q:LASSO减少特征的作用和PCA的降维作用类似吗？</p><p>A:不一样。LASSO的方法是直接减少特征数，做的是特征选择；PCA是通过空间转换将特征空间从高维空间转换到低维空间，是降维。</p><p>当你的特征有很强的语意的时候，PCA的缺点是丢失语意，此时用LASSO更好，如房产数据，这样做后续的分析会更高的保持可解释性；反之，对于你的数据，如果语意性不强，如图像数据，PCA更好。</p><p>Q:使用逻辑回归时怎么利用网格搜索来查找degree,c等超参数<br>A:<a href="https://coding.imooc.com/learn/questiondetail/61679.html" target="_blank" rel="noopener">https://coding.imooc.com/learn/questiondetail/61679.html</a></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fqjaoilapaj31kw0vn41c.jpg" alt></p><p>总的流程</p><ol><li>基本数据情况</li><li>检查数据无效值(NaN,NULL等)</li><li>绘图查看异常点</li><li>删除异常值</li><li>添加新特征</li><li>特征选择</li><li>特征缩放</li><li>应用算法+网格搜索</li></ol><h2 id="机器学习中的一些数学指标"><a href="#机器学习中的一些数学指标" class="headerlink" title="机器学习中的一些数学指标"></a>机器学习中的一些数学指标</h2><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-v09-09-012650.png" alt></p><p>上述的三个数学指标其实本质上都是一样的</p><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-09-012941.png" alt></p><p>基于已有的数学概念进行抽象,得出范数的概念.其实是很简单的.对于右边的没有开根号是不影响最终结果的,有时候也可以叫做L2范数,因为开不开根号变化方向都是一致的,不影响最终结果</p><h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p><a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/" target="_blank" rel="noopener">sklearn 官方模型选择指导</a></p><p><a href="https://docs.microsoft.com/zh-cn/azure/machine-learning/studio/algorithm-cheat-sheet" target="_blank" rel="noopener">Microsoft Azure 官网模型推荐</a></p><h2 id="泰坦尼克存活预测"><a href="#泰坦尼克存活预测" class="headerlink" title="泰坦尼克存活预测"></a>泰坦尼克存活预测</h2><p><a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">Kaggle地址</a>]</p><p><a href="https://zhuanlan.zhihu.com/p/31743196" target="_blank" rel="noopener">参考地址,重点学习一下流程以及模型融合</a><br><a href="https://blog.csdn.net/han_xiaoyang/article/details/49797143" target="_blank" rel="noopener">参考地址2,寒小阳逻辑回归建模</a></p><h2 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h2><p><a href="https://zhuanlan.zhihu.com/p/26890738" target="_blank" rel="noopener">Kaggle机器学习之模型融合（stacking）心得</a></p><p><a href="https://zhuanlan.zhihu.com/p/25836678" target="_blank" rel="noopener">模型融合方法概述</a></p><p><a href="https://jlunevermore.github.io/2016/06/25/14.Bagging%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="noopener">Bagging与随机森林,对西瓜书的一个总结</a></p><h2 id="udacity-总结挺好必看"><a href="#udacity-总结挺好必看" class="headerlink" title="udacity 总结挺好必看"></a>udacity 总结挺好必看</h2><p><a href="http://road2autodrive.info/" target="_blank" rel="noopener">偶像</a></p><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p><a href="https://mp.weixin.qq.com/s/3QFQRL708Muxf_QzKmSMlw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/3QFQRL708Muxf_QzKmSMlw</a></p><h2 id="牛人总结"><a href="#牛人总结" class="headerlink" title="牛人总结"></a>牛人总结</h2><p><a href="https://segmentfault.com/a/1190000012084849" target="_blank" rel="noopener">分享一波关于做Kaggle比赛，Jdata，天池的经验，看完我这篇就够了</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI0NzE3NTAzOA%3D%3D&amp;mid=2652115209&amp;idx=2&amp;sn=003a5e0a8fdc4e4d9755b18031763796#wechat_redirect" target="_blank" rel="noopener">如何建立自己的应用型机器学习流程</a></p><h2 id="Kaggle-入门"><a href="#Kaggle-入门" class="headerlink" title="Kaggle 入门"></a>Kaggle 入门</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA%3D%3D&amp;mid=2650668868&amp;idx=3&amp;sn=ba389178ad651a78e35b3f16bb6ae560#wechat_redirect" target="_blank" rel="noopener">初学者应该参加哪些 Kaggle 比赛</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650670710&amp;idx=1&amp;sn=d75a077506c72eb5ba5d59c063cc0dda&amp;chksm=bec23b0589b5b213e1900c7f963d2e380e4df24726e070ac5f88d9b9e8b1f37bf06b32fe762b&amp;mpshare=1&amp;scene=1&amp;srcid=0409PduieO4ncwIVbg5YsaqW#rd" target="_blank" rel="noopener">Kaggle 六大比赛最全面解析</a></p><h2 id="好的视频资料"><a href="#好的视频资料" class="headerlink" title="好的视频资料"></a>好的视频资料</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650668953&amp;idx=1&amp;sn=68b70229dd96466ef0252ba672002f39&amp;chksm=bec1c2ea89b64bfce5e5a286041d5da8df44fc519b72e999ece90dc8d8b4e75d4862eb8a5a84&amp;mpshare=1&amp;scene=1&amp;srcid=1231OlnWXrdIR0QUx6a5bX2j#rd" target="_blank" rel="noopener">2017年度好视频</a></p><h2 id="深度学习机器学习常见工具包-cheatsheet"><a href="#深度学习机器学习常见工具包-cheatsheet" class="headerlink" title="深度学习机器学习常见工具包 cheatsheet"></a>深度学习机器学习常见工具包 cheatsheet</h2><p><a href="https://github.com/kailashahirwar/cheatsheets-ai" target="_blank" rel="noopener">https://github.com/kailashahirwar/cheatsheets-ai</a></p><h2 id="机器学习所需要的数学知识"><a href="#机器学习所需要的数学知识" class="headerlink" title="机器学习所需要的数学知识"></a>机器学习所需要的数学知识</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650670694&amp;idx=1&amp;sn=687dbfba5890cca3c082a1c373f04ba8&amp;chksm=bec23b1589b5b203a7b78d689b6469392a11133e9ae3558d71130cb75cf57dba1287c3de529d&amp;mpshare=1&amp;scene=1&amp;srcid=0409NwpiY3TIBsTdYowz87zC#rd" target="_blank" rel="noopener">一文读懂机器学习需要哪些数学知识</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650670670&amp;idx=1&amp;sn=8b3c114e542843a81599dcf6c8441e8d&amp;chksm=bec23b3d89b5b22bc37d6202a0276cd7824b38a617c1f1deab0d70d63b35ec48db735124b2b4&amp;mpshare=1&amp;scene=1&amp;srcid=0409cR4X0hRgCTEqKh383YaN#rd" target="_blank" rel="noopener">机器学习数学知识</a></p><h2 id="Google-发布关于机器学习工程的最佳实践"><a href="#Google-发布关于机器学习工程的最佳实践" class="headerlink" title="Google 发布关于机器学习工程的最佳实践"></a>Google 发布关于机器学习工程的最佳实践</h2><p><a href="https://mp.weixin.qq.com/s/Jh-55wfvY6DByniDK2MIRQ" target="_blank" rel="noopener">点我查看 google 的最佳实践</a></p><h2 id="如何通过网格搜索来寻找自定义的Pipeline模型-比如自定义的多项式线性模型"><a href="#如何通过网格搜索来寻找自定义的Pipeline模型-比如自定义的多项式线性模型" class="headerlink" title="如何通过网格搜索来寻找自定义的Pipeline模型(比如自定义的多项式线性模型)"></a>如何通过网格搜索来寻找自定义的Pipeline模型(比如自定义的多项式线性模型)</h2><p><a href="https://coding.imooc.com/learn/questiondetail/61679.html" target="_blank" rel="noopener">https://coding.imooc.com/learn/questiondetail/61679.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/machineLearning.png&quot; alt&gt;&lt;br&gt;机器学习备注
    
    </summary>
    
    
    
      <category term="数据分析" scheme="http://zjsnowman.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>深度学习备注</title>
    <link href="http://zjsnowman.com/2018/11/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/"/>
    <id>http://zjsnowman.com/2018/11/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/</id>
    <published>2018-11-22T03:30:05.000Z</published>
    <updated>2019-10-21T02:55:51.583Z</updated>
    
    <content type="html"><![CDATA[<p>Deep Learning!<a id="more"></a></p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><ul><li>Sigmod 二分类问题 Y是(0,1),适合使用Sigmod函数</li><li>TanH 隐藏层推荐使用,值域为(-1,1),可以起到中心化的作用</li><li>ReLU 因为TanH收敛太慢了,采用ReLu可以加快收敛,也是目前深度学习模型默认的激活函数</li></ul><h2 id="分类问题的损失函数-交叉熵-Cross-Entropy-Loss"><a href="#分类问题的损失函数-交叉熵-Cross-Entropy-Loss" class="headerlink" title="分类问题的损失函数:交叉熵(Cross Entropy Loss)"></a>分类问题的损失函数:交叉熵(Cross Entropy Loss)</h2><p>神经网络模型的效果及优化的目标是通过损失函数来定义的。</p><p>回归问题常用的损失函数是均方误差( MSE，mean squared error )。</p><p>分类问题常用的损失函数为交叉熵( Cross Entropy Loss)<br>交叉熵具体解释可以参考(<a href="https://blog.csdn.net/xg123321123/article/details/80781611" target="_blank" rel="noopener">https://blog.csdn.net/xg123321123/article/details/80781611</a>)</p><h2 id><a href="#" class="headerlink" title=" "></a> </h2><p>完全连接层(Fully Connected Layer)<br>局部连接层(Local Connected Layer)<br>池化层(Pooling Layer) 降低纬度,防止过拟合<br>图片增强 - 对训练集随机进行平移,旋转等操作</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deep Learning!
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习经典案例学习</title>
    <link href="http://zjsnowman.com/2018/10/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0/"/>
    <id>http://zjsnowman.com/2018/10/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0/</id>
    <published>2018-10-29T02:30:12.000Z</published>
    <updated>2019-10-21T03:18:22.580Z</updated>
    
    <content type="html"><![CDATA[<p>操千曲而后晓声，观千剑而后识器<a id="more"></a></p><h2 id="Kaggle-房价预测"><a href="#Kaggle-房价预测" class="headerlink" title="Kaggle 房价预测"></a>Kaggle 房价预测</h2><p><a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" target="_blank" rel="noopener">题目</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650664654&amp;idx=2&amp;sn=125a225281b8b3a170ba6908c9233713&amp;chksm=bec1d3bd89b65aab121ec0ef49a51a9a1567dfded9c4ebbae7134a74c1465cffa1de84a6003e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">答案</a></p><p>总结:</p><h2 id="解决问题的框架"><a href="#解决问题的框架" class="headerlink" title="解决问题的框架"></a>解决问题的框架</h2><ul><li><p>理解问题：查看每个变量并且根据他们的意义和对问题的重要性进行哲学分析。</p></li><li><p>单因素研究：只关注因变量( SalePrice)，并且进行更深入的了解。</p></li><li><p>多因素研究：分析因变量和自变量之间的关系。</p></li><li><p>基础清洗：清洗数据集并且对缺失数据，异常值和分类数据进行一些处理。</p></li><li><p>检验假设：检查数据是否和多元分析方法的假设达到一致。</p></li></ul><h2 id="学习使用相关系数矩阵热力图"><a href="#学习使用相关系数矩阵热力图" class="headerlink" title="学习使用相关系数矩阵热力图"></a>学习使用相关系数矩阵热力图</h2><ul><li>看出Y和不同X之间的相关性</li><li>看出不同X之间的共轭性,也就是双胞胎特征,可以只用一个就可以了</li></ul><h2 id="确实值处理的方法"><a href="#确实值处理的方法" class="headerlink" title="确实值处理的方法"></a>确实值处理的方法</h2><ul><li>当超过 15% 的数据都缺失的时候，我们应该删掉相关变量且假设该变量并不存在(删除列)。</li><li>当某个特征缺失少量观察值,可以把相应的记录删掉(删除行)<br><br><a href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python" target="_blank" rel="noopener">Kaggle 原答案</a></li></ul><h2 id="O2O优惠券使用预测"><a href="#O2O优惠券使用预测" class="headerlink" title="O2O优惠券使用预测"></a>O2O优惠券使用预测</h2><p><a href="https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.11409106.5678.1.41b26b27EWjjMo&amp;raceId=231593" target="_blank" rel="noopener">题目</a><br><a href="https://tianchi.aliyun.com/notebook/detail.html?spm=5176.8366600.0.0.2fb6311f90pu6X&amp;id=4796" target="_blank" rel="noopener">参考答案</a></p><p>总结:</p><p>- 这个是一个分类问题,确定好metric是AUC.理解什么是AUC</p><ul><li>这里提高AUC的关键是特征,所以好的特征工程(特征提取)非常重要.<br>确定好之后可以用模型融合来提高成绩</li></ul><p>- 再求AUC值得时候<br><code>y_score : array, shape = [n_samples] or [n_samples, n_classes]Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by “decision_function” on some classifiers). For binary y_true, y_score is supposed to be the score of the class with greater label.</code><br>y可以用<code>decision_fuction</code>的返回值,也可以用<code>predict_proba</code>的返回值</p><h2 id="Kaggle官方机器学习教程"><a href="#Kaggle官方机器学习教程" class="headerlink" title="Kaggle官方机器学习教程"></a>Kaggle官方机器学习教程</h2><p><a href="https://www.kaggle.com/learn/machine-learning" target="_blank" rel="noopener">教程</a></p><p><a href="https://www.kaggle.com/dansbecker/handling-missing-values" target="_blank" rel="noopener">缺失值处理</a></p><ul><li>直接丢弃行或者列</li><li>补全,均值补全或者其他策略</li><li>对有缺失的列添加额外的列(是否缺失)来标识</li></ul><h2 id="天池比赛从0-1分享"><a href="#天池比赛从0-1分享" class="headerlink" title="天池比赛从0-1分享"></a>天池比赛从0-1分享</h2><p><a href="https://tianchi.aliyun.com/forum/videoStream.html?spm=5176.11817089.0.0.6e8143919ushgM&amp;postsId=5594#postsId=5594" target="_blank" rel="noopener">视频分享地址</a><br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-11-19-112417.png" alt><br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-11-19-112248.png" alt></p><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-11-19-112552.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;操千曲而后晓声，观千剑而后识器
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>运营数据分析</title>
    <link href="http://zjsnowman.com/2018/10/08/%E8%BF%90%E8%90%A5%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    <id>http://zjsnowman.com/2018/10/08/%E8%BF%90%E8%90%A5%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</id>
    <published>2018-10-08T14:18:21.000Z</published>
    <updated>2019-10-21T02:55:51.587Z</updated>
    
    <content type="html"><![CDATA[<p>运营相关数据分析体系<a id="more"></a></p><h1 id="APP基础数据分析体系"><a href="#APP基础数据分析体系" class="headerlink" title="APP基础数据分析体系"></a>APP基础数据分析体系</h1><p><a href="http://www.niaogebiji.com/article-13835-1.html" target="_blank" rel="noopener">http://www.niaogebiji.com/article-13835-1.html</a></p><ul><li>用户规模和质量<ul><li>活跃用户,日活,周活,月活</li><li>新增商户,日增,周增,月增(衡量营销效果,关注留存)</li><li>用户构成,比如月活具体构成,回流,连续N月活跃</li><li>留存.次日,7日,14日以及30日留存率</li><li>每个用户活跃总天数</li></ul></li><li>参与度<ul><li>启动次数.一定周期内启动次数</li><li>使用时长</li><li>访问页面</li><li>使用时间间隔</li></ul></li><li>渠道分析</li><li><p>功能分析</p><ul><li>功能活跃</li><li>页面访问路径</li><li>漏斗模型</li></ul></li><li><p>用户属性分析</p><ul><li>终端设备</li><li>网络以及运营商</li><li>地域分析</li><li>用户画像分析</li></ul></li></ul><h1 id="数据运营十大数据分析方法"><a href="#数据运营十大数据分析方法" class="headerlink" title="数据运营十大数据分析方法"></a>数据运营十大数据分析方法</h1><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fw8qgce159j30xc0isgn2.jpg" alt><br><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fw8qhg26zjj313k0n675d.jpg" alt><br>数据分析方法补充:</p><ul><li>优化建模 当设计到预测和分类的场景的时候,通过数据挖掘的手段可以处理这种需求</li></ul><h1 id="数据采集分析"><a href="#数据采集分析" class="headerlink" title="数据采集分析"></a>数据采集分析</h1><p><a href="https://zhuanlan.zhihu.com/p/21628977?refer=sangwf" target="_blank" rel="noopener">神策桑文峰对当前数据采集的一个精彩分析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;运营相关数据分析体系
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>解密文章</title>
    <link href="http://zjsnowman.com/2018/06/25/%E5%8A%A0%E5%AF%86%E6%96%87%E7%AB%A0/"/>
    <id>http://zjsnowman.com/2018/06/25/%E5%8A%A0%E5%AF%86%E6%96%87%E7%AB%A0/</id>
    <published>2018-06-25T04:03:26.000Z</published>
    <updated>2019-10-21T02:55:51.581Z</updated>
    
    <content type="html"><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">方便查看</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> U2FsdGVkX18++k7fyzWRZxBSO/46nvXG9CzoBFJT8F3dgs/PZ8pNzc2kl7k4bXYzf/bUy8AGl4xysK1n8qpDZFMoDqkKlaBMq0XzqNFVMN7orC1QcyKkRjCfFmhUkx56wMJNj9U+vcHqakVYPnCRaN44mUQ3YrKagzXbGaSqhULq+aCWvMOeDrAEnoD/sNhiHeNpd9s6iG6rdpoLAzI6petybtNrAsukpm3aL3qHNjryDSXpsQivaO/AyfJawjCjPR+83cyI8Rf55S6++UFP8MG4fSY/PjCmG1an95boHk4o9eIiudmwHCEPhIe/7sJbTq+ioUunjfbxRDPMMBkJPtD0EJ+i8Q1XftZ/ju4vP/IXMYapdfNyQCVtzUkN5AtNFFFKuNnexosYuHocSGacU15DMtfNOnRltwCO+xm5Y2kSJ3xbXgoMCXsCWMmc2hmi3PiQRYI8wkCdOZM1mHF6jjTmUq6mn21lMWG0EJV3h0TaJSM9VVQyqEEPrGVjtHikt96gBQVT/DBZLmveD7Diu55gJ8WgDsW0jtms7hwoONlBGmi/pqEppT2NjNyNs0mHpEmHeme+rcnSWKz89XbOPfU8tZYvCNx517Aa1UZZ3ntVuwBW4HJmib6WBZ7d0BcVZdoG+BjPFMuD5m0wVSiF4w== </div>]]></content>
    
    <summary type="html">
    
      一些不错的文章,暂时放到这
    
    </summary>
    
    
    
      <category term="加密" scheme="http://zjsnowman.com/tags/%E5%8A%A0%E5%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>大数据调度系统 azkaban 学习备注</title>
    <link href="http://zjsnowman.com/2018/06/22/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F-azkaban-%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/"/>
    <id>http://zjsnowman.com/2018/06/22/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F-azkaban-%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/</id>
    <published>2018-06-22T06:18:45.000Z</published>
    <updated>2019-10-21T02:55:51.581Z</updated>
    
    <content type="html"><![CDATA[<p>目前在使用 Spark 来处理数据,因为不同的任务之间具有依赖关系, <code>corntab</code>满足不了.所以决定使用 azkaban 的进行任务调度.<a id="more"></a></p><h2 id="学习文档"><a href="#学习文档" class="headerlink" title="学习文档"></a>学习文档</h2><p><a href="https://blog.csdn.net/hblfyla/article/details/74384915" target="_blank" rel="noopener">azkaban 简单介绍与使用</a></p><p><a href="https://azkaban.github.io/" target="_blank" rel="noopener">azkaban 官网</a></p><p><a href="https://blog.csdn.net/lsshlsw/article/details/50831239" target="_blank" rel="noopener">azkaban调度 spark 任务</a></p><p><a href="https://www.cnblogs.com/qingyunzong/category/1197848.html" target="_blank" rel="noopener">azkaban 最全的一个教程</a></p><ul><li>配置邮件</li><li>配置时区</li></ul><p>注意启动和停止 azkaban 都需要在 使用<code>bin/start-solo.sh</code>,而不能进到 bin 目录里面直接<br>执行<code>./start-solo.sh</code>.坑爹.这里耦合的比较严重,是一个坑.注意!!!</p><h2 id="动态传参"><a href="#动态传参" class="headerlink" title="动态传参"></a>动态传参</h2><p>写了一个 spark清洗脚本,需要清理具体日期的日志.这里需要动态的传入时间进去.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type=command</span><br><span class="line">date=2018-06-23</span><br><span class="line">command=spark-submit --master yarn /opt/appl/sparkLogAnalysis/elasticsearch-spark.py $&#123;date&#125;</span><br><span class="line">notify.emails=xxx@xxx.com,xx@xxx.com  # 成功失败后发送邮件</span><br></pre></td></tr></table></figure></p><p>这里通过引用的方式传入时间参数,这样在 azkaban的 web 界面上就可以直接编辑参数<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044120.jpg" alt></p><p>这里涉及到 azkaban 一个比较复杂的传参,通过 job 自身支持的参数替换来作为 shell脚本的入参,然后在 shell 脚板中通过$1,$2的方式来引用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">type=command</span><br><span class="line">host=http://host:port</span><br><span class="line">index=logstash-2018*</span><br><span class="line">doc_type=mbpgtw-interface</span><br><span class="line">date=2018-06-26</span><br><span class="line">limit=10000</span><br><span class="line">command=bash /opt/appl/sparkLogAnalysis/load_data_from_es.sh $&#123;host&#125; $&#123;index&#125; $&#123;doc_type&#125; $&#123;date&#125; $&#123;limit&#125;</span><br><span class="line">notify.emails=zhangjun@iboxpay.com,wuze@iboxpay.com</span><br></pre></td></tr></table></figure></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">elasticdump \</span><br><span class="line">  --input=<span class="variable">$1</span>/<span class="variable">$2</span>/<span class="variable">$3</span> \</span><br><span class="line">  --output=/opt/appl/es_data/mbpgtw-interface-<span class="variable">$4</span>.json \</span><br><span class="line">  --<span class="built_in">limit</span> <span class="variable">$5</span> \</span><br><span class="line">  --sourceOnly <span class="literal">true</span> \</span><br><span class="line">  --searchBody <span class="string">'&#123;"query": &#123;</span></span><br><span class="line"><span class="string">        "range": &#123;</span></span><br><span class="line"><span class="string">            "@timestamp": &#123;</span></span><br><span class="line"><span class="string">                "gte": "'</span><span class="variable">$4</span><span class="string">' 00:00:00",   #在字符串中要把$4用单引号在包一层来达到替换的目的</span></span><br><span class="line"><span class="string">                "lte": "'</span><span class="variable">$4</span><span class="string">' 23:59:59",</span></span><br><span class="line"><span class="string">                "format":"yyyy-MM-dd HH:mm:ss",</span></span><br><span class="line"><span class="string">                "time_zone":"+08:00"</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;'</span></span><br></pre></td></tr></table></figure><p>这里如果需要动态的更改时间的话,是这样做的.时间(date)参数就不要在 job 里面定义.在 shell 脚本里面去弄.具体代码如下:<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line">yesterday=`date -d <span class="string">"1 days ago"</span> +%Y-%m-%d`  </span><br><span class="line"><span class="comment">#这里注意不是单引号,而是键盘波浪号下面的符号,应该不是中文符号, MarkDown 里面行间代码也是这个符号</span></span><br><span class="line">elasticdump \</span><br><span class="line">  --input=<span class="variable">$1</span>/<span class="variable">$2</span>/<span class="variable">$3</span> \</span><br><span class="line">  --output=/opt/appl/es_data/<span class="variable">$3</span>-<span class="variable">$yesterday</span>.json \</span><br><span class="line">  --<span class="built_in">limit</span> <span class="variable">$4</span> \</span><br><span class="line">  --sourceOnly <span class="literal">true</span> \</span><br><span class="line">  --searchBody <span class="string">'&#123;"query": &#123;</span></span><br><span class="line"><span class="string">        "range": &#123;</span></span><br><span class="line"><span class="string">            "@timestamp": &#123;</span></span><br><span class="line"><span class="string">                "gte": "'</span><span class="variable">$yesterday</span><span class="string">' 00:00:00",</span></span><br><span class="line"><span class="string">                "lte": "'</span><span class="variable">$yesterday</span><span class="string">' 23:59:59",</span></span><br><span class="line"><span class="string">                "format":"yyyy-MM-dd HH:mm:ss",</span></span><br><span class="line"><span class="string">                "time_zone":"+08:00"</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;'</span></span><br></pre></td></tr></table></figure></p><p><a href="https://www.codetd.com/article/1728733" target="_blank" rel="noopener">shell 传参可以参考这个</a></p><h3 id="公共参数"><a href="#公共参数" class="headerlink" title="公共参数"></a>公共参数</h3><p>可以定义一个<code>system.properties</code>文件,里面定义key-value.<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044124.jpg" alt></p><p>这样多个 job 之间可以共享<code>system.properties</code>里面定义的字段.一样也是通过${xxx}的方式在 job 文件中引用.</p><h2 id="一些注意事项"><a href="#一些注意事项" class="headerlink" title="一些注意事项"></a>一些注意事项</h2><ul><li>一个flow的email属性，只会取最后一个job的配置，其他的job的email配置将会被忽略<br><code>java.lang.UnsupportedClassVersionError: azkaban/soloserver/AzkabanSingleServer : Unsupported major.minor version 52.0</code> 出现这种错误,是 Java 版本太低导致的,更新到java8 即可</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前在使用 Spark 来处理数据,因为不同的任务之间具有依赖关系, &lt;code&gt;corntab&lt;/code&gt;满足不了.所以决定使用 azkaban 的进行任务调度.
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>统计学学习笔记</title>
    <link href="http://zjsnowman.com/2018/06/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    <id>http://zjsnowman.com/2018/06/15/%E7%BB%9F%E8%AE%A1%E5%AD%A6/</id>
    <published>2018-06-15T09:33:17.000Z</published>
    <updated>2019-10-21T02:55:51.586Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/importrantData.jpg" alt><br>数据分析的一些总结和笔记<a id="more"></a></p><h1 id="明确几个概念"><a href="#明确几个概念" class="headerlink" title="明确几个概念"></a>明确几个概念</h1><ul><li>大学的学的概率论与数理统计其实是由概率学和统计学两部分组成的。现在重点学习一下统计学</li><li>统计学可以分为两种：描述统计学和推论统计学。描述统计学相对简单，大部分都知道。就是统计数据的<br>具体参数。比如平均数，众数，中位数，方差等等。推论统计学就比较厉害了。核心理论是大数定理。核心内容是<br>抽样分布，参数估计和假设检验。</li><li>概念不清，建议购买一本教材。推荐中国人民大学出版社的&lt;&lt;统计学&gt;&gt;第六版,作者贾俊平，何晓群等</li></ul><h1 id="数据分析基本入门方法"><a href="#数据分析基本入门方法" class="headerlink" title="数据分析基本入门方法"></a>数据分析基本入门方法</h1><ul><li>数据分析基本分析方法：相关并不代表因果（correlation doen not prove causation）,两个变量相关并不意味着其中一个是另一个发生的原因。</li><li>随机样本的解释：每个对象被选中的概率是一样的。</li></ul><h1 id="集中趋势"><a href="#集中趋势" class="headerlink" title="集中趋势"></a>集中趋势</h1><ul><li>平均数的缺点：当有异常值得时候，数据分布会被拉偏，得出的结论也具有误导性。这方面众数可以弥补。<h2 id="涉及到一些中英对照"><a href="#涉及到一些中英对照" class="headerlink" title="涉及到一些中英对照"></a>涉及到一些中英对照</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">均值-&gt;mean</span><br><span class="line">中位数 -&gt;median</span><br><span class="line">众数-&gt;mode</span><br><span class="line">偶数-&gt;even</span><br><span class="line">奇数-&gt;odd</span><br><span class="line">正态分布-&gt;Normal</span><br><span class="line">双峰分布-&gt;Bimodal</span><br><span class="line">偏斜分布-&gt;Skewed</span><br><span class="line">均匀分布-&gt;Uniform</span><br><span class="line">箱线图-&gt;Boxplots</span><br><span class="line">直方图-&gt;Histogram</span><br></pre></td></tr></table></figure></li></ul><h1 id="方差的一些注意点"><a href="#方差的一些注意点" class="headerlink" title="方差的一些注意点"></a>方差的一些注意点</h1><p>方差可以分为两种，样本方差和总体方差。在 Google 表格中对应的函数分别是 Stdev 和 Stdevp.<br>在实际过程中往往我们是不知道总体方差的，所以通常使用样本方差去估计总体方差。所以通过贝塞尔校正系数<br>来弥补这样带来的缺陷。</p><h1 id="标准差与标准误"><a href="#标准差与标准误" class="headerlink" title="标准差与标准误"></a>标准差与标准误</h1><ul><li>这个容易混淆。具体可以参考这篇论文，讲的非常清晰。<a href="http://blog.sciencenet.cn/upload/blog/file/2010/12/20101226211028645.pdf" target="_blank" rel="noopener">让我来替你弄清楚他们两个吧</a></li><li>Standard deviation of the sampling distribution （抽样分布的标准偏差）<br>=stand error （标准误差）</li></ul><p>这里深刻理解两者的含义就很好理解.两者的对象不同.<br>标准差针对的是个体之间的差异,是整个 <strong>样本对样本</strong> 平均数的离散程度 ,是数据精密度的衡量指标<br>而标准误差反映 <strong>样本平均数对总体平均数</strong> 的变异程度 ,从而反映抽样误差的大小,是量度结果精密度的指标</p><h1 id="抽样分布"><a href="#抽样分布" class="headerlink" title="抽样分布"></a>抽样分布</h1><blockquote><p>如果从容量为N的有限总体抽样，若每次抽取容量为n的样本，那么一共可以得到N取n的组合个样本(所有可能的样本个数)。抽样所得到的每一个样本可以计算一个平均数，全部可能的样本都被抽取后可以得到许多平均数。如果将抽样所得到的所有可能的样本平均数集合起来便构成一个新的总体，平均数就成为这个新总体的变量。由平均数构成的新总体的分布，称为 <strong>平均数的抽样分布</strong> 。随机样本的任何一种统计数都可以是一个变量，这种变量的分布称为统计数的抽样分布。</p><p>如果特指的统计量是样本均值，则此分布为均值的抽样分布。类似的有标准差、方差、中位数、比例的抽样分布。</p></blockquote><h1 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h1><ul><li>理解点估计和区间估计</li><li>正确理解置信区间</li><li>根据样本量，总体方差是否已知，是否是正态分布来正确选择总体均值的区间估计计算公式</li><li>一个总体参数和两个总体参数的区间估计方式不同</li><li>在两个总体参数内部根据样本数量不同计算方式也不同。小样本情况下可能会涉及到总体方差的合并</li></ul><h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><ul><li><p>Cohen’s d 的含义<br><img src="/images/Cohen.png" alt="以标准偏差作为单位，这些均值之间相差多少"></p></li><li><p>相依样本或者重复试验。一般有一下几种。</p><ol><li>Repeated measures design -&gt;重复衡量设计  </li><li>Longitudinal design -&gt;纵向设计</li><li>Pretest posttest-&gt;预期检验 后期检验</li></ol></li></ul><p><em>总的来说就是只有一个总体参数，好处是节约成本，坏处是有残留效应</em></p><ul><li>独立样本</li></ul><p><em>总的来说就是有两个总体参数。好处坏处与上面相反</em></p><ul><li>理解 P值</li><li>我们应说“保留零假设”或“未能拒绝零假设”，而不是“接受零假设。</li><li>理解什么时候用单测或者双侧校验。</li><li>同上根据总体参数数量，样本数量，总体方差是否一致，采用不同的方式来进行校验。</li></ul><h1 id="一些概念通俗理解"><a href="#一些概念通俗理解" class="headerlink" title="一些概念通俗理解"></a>一些概念通俗理解</h1><h2 id="协方差与相关系数"><a href="#协方差与相关系数" class="headerlink" title="协方差与相关系数"></a>协方差与相关系数</h2><p><a href="https://www.zhihu.com/question/20852004" target="_blank" rel="noopener">参考知乎上这个通俗解释</a></p><p>总结一下就是:</p><ul><li><p>如果协方差为正,说明X,Y同向变化,协方差越大说明同向程度越高.反之,说明X,Y 反向运动,协方差绝对值越大,说明反向程度越大</p></li><li><p>相关系数就是对协方差的一个标准化.用于评判(X1,Y1)和(X2,Y2)不同对之间的相关性.</p></li><li><p>协方差只能描述线性关系，也就是说当协方差为零的时候也不能说变量之间没有关系，只能说没有线性关系，另外协方差是有单位的，且没有范围，所以人们发明了相关系数，相关系数就是协方差的标准化形式，范围是(-1,1)，一样，为零不能说明变量之间没有关系，只能说没有线性关系，有可能有非线性关系，比如平方，这个时候可以看看散点图，数字和图结合来看。</p></li></ul><h2 id="自相关系数和偏自相关系数"><a href="#自相关系数和偏自相关系数" class="headerlink" title="自相关系数和偏自相关系数"></a>自相关系数和偏自相关系数</h2><p><a href="https://zhuanlan.zhihu.com/p/26525852" target="_blank" rel="noopener">参考这个可以对自相关有个理解</a></p><h2 id="排列与组合"><a href="#排列与组合" class="headerlink" title="排列与组合"></a>排列与组合</h2><p><a href="https://www.zhihu.com/question/26094736" target="_blank" rel="noopener">知乎通俗解释</a><br>总结:</p><ul><li>排列关注取出一定情况下,在内部再进行一次排列</li><li>组合只关注取出的情况,不关注内部排列顺序</li></ul><h2 id="箱线图"><a href="#箱线图" class="headerlink" title="箱线图"></a>箱线图</h2><p><a href="https://www.zhihu.com/question/36172806" target="_blank" rel="noopener">箱形图为什么能检测异常值，原理是什么？</a><br>箱线图有两种功能:</p><ul><li>检查异常值,如果你认为数据里面有异常值的话</li><li>看数据整体分布.如果你认为数据里面都是正常值.</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="频率主义-传统经典统计学-和贝叶斯主义"><a href="#频率主义-传统经典统计学-和贝叶斯主义" class="headerlink" title="频率主义(传统经典统计学)和贝叶斯主义"></a>频率主义(传统经典统计学)和贝叶斯主义</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzI4MTQ2NjU5NA==&amp;mid=2247486822&amp;idx=1&amp;sn=02b4856b6f0fb6e0e10f4abcf1b5ec22&amp;chksm=eba98eebdcde07fdb0bb461fb19f9f27482a01b201b1b5ecbc7f87860b2515c7f51ce933fb14&amp;mpshare=1&amp;scene=1&amp;srcid=0425psSvTEvUpCvHJK81cJAi#rd" target="_blank" rel="noopener">参考这个实现</a></p><p><a href="http://students.brown.edu/seeing-theory/cn.html" target="_blank" rel="noopener">布兰大学根据统计学做的可视化,更好的理解统计学</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/importrantData.jpg&quot; alt&gt;&lt;br&gt;数据分析的一些总结和笔记
    
    </summary>
    
    
    
      <category term="数据分析" scheme="http://zjsnowman.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>自动化运维</title>
    <link href="http://zjsnowman.com/2018/06/07/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    <id>http://zjsnowman.com/2018/06/07/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/</id>
    <published>2018-06-07T10:04:52.000Z</published>
    <updated>2019-10-21T02:55:51.586Z</updated>
    
    <content type="html"><![CDATA[<p>自动化运维<a id="more"></a></p><h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="http://showme.codes/2018-06-07/devops-in-action/?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="noopener">http://showme.codes/2018-06-07/devops-in-action/?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a></p><p><a href="https://landing.google.com/sre/book/index.html" target="_blank" rel="noopener">https://landing.google.com/sre/book/index.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;自动化运维
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>时间序列分析</title>
    <link href="http://zjsnowman.com/2018/06/01/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/"/>
    <id>http://zjsnowman.com/2018/06/01/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/</id>
    <published>2018-06-01T08:48:23.000Z</published>
    <updated>2019-10-21T02:55:51.582Z</updated>
    
    <content type="html"><![CDATA[<p>时间序列分析<a id="more"></a></p><h1 id="自相关函数-ACF-和偏自相关系数-PACF"><a href="#自相关函数-ACF-和偏自相关系数-PACF" class="headerlink" title="自相关函数(ACF )和偏自相关系数(PACF)"></a>自相关函数(ACF )和偏自相关系数(PACF)</h1><p><a href="https://www.ibm.com/support/knowledgecenter/zh/SS3RA7_sub/modeler_mainhelp_client_ddita/components/dt/timeseries_acf_pacf.html" target="_blank" rel="noopener">参考这个解释</a></p><h1 id="帮助理解"><a href="#帮助理解" class="headerlink" title="帮助理解"></a>帮助理解</h1><p>&lt;&lt;时间序列分析基于 R&gt;&gt;第40页对北京市城市居民定期存储所占比例的平稳性与纯随机性进行检验<br>通过这个例子帮助理解</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;时间序列分析
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>轻量http性能测试工具 wrk</title>
    <link href="http://zjsnowman.com/2018/05/28/%E8%BD%BB%E9%87%8Fhttp%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7-wrk/"/>
    <id>http://zjsnowman.com/2018/05/28/%E8%BD%BB%E9%87%8Fhttp%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7-wrk/</id>
    <published>2018-05-28T03:11:01.000Z</published>
    <updated>2019-10-21T02:55:51.587Z</updated>
    
    <content type="html"><![CDATA[<p>wrk是一个轻量的 http 性能测试工具,方便开发人员快速验证<a id="more"></a></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>性能 测试一般有专门的工具来供测试人员适应,比如 Jmeter, 但是一般安装使用都比较麻烦. wrk是一个简单的性能测试工具,能做很多基本的性能测试.</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h2><p><code>brew install wrk</code></p><h2 id="其他系统"><a href="#其他系统" class="headerlink" title="其他系统"></a>其他系统</h2><p><a href="https://github.com/wg/wrk" target="_blank" rel="noopener">官网</a></p><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p><code>wrk -t4 -c1000 -d30s -T30s --latency http://www.douban.com</code><br>上面这条命令的意思是用4个线程来模拟1000个并发连接，整个测试持续30秒，连接超时30秒，打印出请求的延迟统计信息。</p><p>需要注意的是 wrk 使用异步非阻塞的 io，并不是用线程去模拟并发连接，因此不需要设置很多的线程，一般根据 CPU 的核心数量设置即可。另外 -c 参数设置的值必须大于 -t 参数的值。</p><p>输出的结果如:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Running 30s test @ http://www.douban.com</span><br><span class="line">  4 threads and 1000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency     1.15s     1.60s   20.83s    91.57%</span><br><span class="line">    Req/Sec   292.32     50.28   450.00     70.05%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  546.96ms</span><br><span class="line">     75%    1.21s</span><br><span class="line">     90%    2.46s</span><br><span class="line">     99%    8.59s</span><br><span class="line">  34832 requests in 30.01s, 11.03MB read</span><br><span class="line">  Non-2xx or 3xx responses: 34832</span><br><span class="line">Requests/sec:   1160.84</span><br><span class="line">Transfer/sec:    376.36KB</span><br></pre></td></tr></table></figure></p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="http://zjumty.iteye.com/blog/2221040" target="_blank" rel="noopener">http://zjumty.iteye.com/blog/2221040</a></p><p><a href="http://www.restran.net/2016/09/27/wrk-http-benchmark/" target="_blank" rel="noopener">http://www.restran.net/2016/09/27/wrk-http-benchmark/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;wrk是一个轻量的 http 性能测试工具,方便开发人员快速验证
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>大数据相关技术</title>
    <link href="http://zjsnowman.com/2018/05/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/"/>
    <id>http://zjsnowman.com/2018/05/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/</id>
    <published>2018-05-23T02:12:41.000Z</published>
    <updated>2019-10-21T02:55:51.581Z</updated>
    
    <content type="html"><![CDATA[<p>大数据技术涉及到一些基本概念<a id="more"></a></p><h1 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h1><p>Hadoop=HDFS(分布式文件系统)+MapReduce(分布式计算)</p><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><h3 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h3><p>数据块是抽象块而非整个文件作为存储单元<br>默认是64M, 一般设置128M,备份 X3</p><h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><ul><li>管理文件系统的命名空间,存放文件元数据</li><li>维护着文件系统的所有文件和目录,文件与数据块的映射</li><li>记录每个文件中各个块所在数据节点的信息</li></ul><h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><ul><li>存储并检索数据块</li><li>向 NameNode更新所存储的列表</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>不适合大量小文件存储</li><li>不适合并发写入, 不支持文件随机更改</li><li>不支持随机读等低延迟的方式</li></ul><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><ul><li>shell 操作  通过<code>hadoop fs -option</code></li><li>python 操作 通过<code>hdfs3</code>这个包来和 hdfs 交互</li></ul><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><h3 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h3><h4 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h4><ul><li>分配和调度资源</li><li>启动并监控 ApplicationMaster</li><li>监控NodeManager<h4 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h4></li><li>管理单个节点的资源</li><li>处理来自ResourceManager的命令</li><li><p>处理来自 ApplicationMaster 的命令</p><h4 id="ApplicationMaster"><a href="#ApplicationMaster" class="headerlink" title="ApplicationMaster"></a>ApplicationMaster</h4></li><li><p>为 MapReduce类型的程序申请资源,并分配给内部任务</p></li><li>负责数据的切分</li><li>监控任务的执行和容错</li></ul><h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044021.jpg" alt></p><h2 id="Hadoop-生态"><a href="#Hadoop-生态" class="headerlink" title="Hadoop 生态"></a>Hadoop 生态</h2><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044037.jpg" alt></p><h3 id="HBase-Hadoop-database"><a href="#HBase-Hadoop-database" class="headerlink" title="HBase( Hadoop database)"></a>HBase( Hadoop database)</h3><p>HBase 是一个分布式数据库</p><ul><li>利用HDFS 作为文件存储系统,支持MR程序读取数据</li><li>存储非结构化和半结构化数据</li></ul><h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044101.jpg" alt></p><ul><li>Spark是 <strong>基于内存计算</strong> 的大数据并行计算框架</li><li>Spark 是MapReduce的替代方案,兼容 HDFS,HIVE 等数据源</li></ul><h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3><p>Hive 是SQL 解析引擎,他将SQL 语句转移成MR 操作,然后在 hadoop 上执行<br>定义了一种类 SQL 语言:HQL(类似但不是完全相同)</p><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044114.jpg" alt="Hive 体系架构"></p><h3 id="Spark-外部数据"><a href="#Spark-外部数据" class="headerlink" title="Spark 外部数据"></a>Spark 外部数据</h3><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044115.jpg" alt></p><h3 id="离线数据处理架构"><a href="#离线数据处理架构" class="headerlink" title="离线数据处理架构"></a>离线数据处理架构</h3><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-044119.jpg" alt></p><h1 id="推荐使用版本"><a href="#推荐使用版本" class="headerlink" title="推荐使用版本"></a>推荐使用版本</h1><p><a href="http://archive.cloudera.com/cdh5/cdh/5/o" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/o</a></p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">Hadoop文档</a></p><p><a href="https://hive.apache.org/" target="_blank" rel="noopener">Hive</a></p><p><a href="https://spark-packages.org/" target="_blank" rel="noopener">Spark 第三方包</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大数据技术涉及到一些基本概念
    
    </summary>
    
    
    
      <category term="数据分析" scheme="http://zjsnowman.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>记一次 Python 处理日志速度优化</title>
    <link href="http://zjsnowman.com/2018/05/15/%E8%AE%B0%E4%B8%80%E6%AC%A1-Python-%E5%A4%84%E7%90%86%E6%97%A5%E5%BF%97%E9%80%9F%E5%BA%A6%E4%BC%98%E5%8C%96/"/>
    <id>http://zjsnowman.com/2018/05/15/%E8%AE%B0%E4%B8%80%E6%AC%A1-Python-%E5%A4%84%E7%90%86%E6%97%A5%E5%BF%97%E9%80%9F%E5%BA%A6%E4%BC%98%E5%8C%96/</id>
    <published>2018-05-15T01:45:02.000Z</published>
    <updated>2019-10-21T02:55:51.586Z</updated>
    
    <content type="html"><![CDATA[<p>通过 Python+ Pandas +regrex清洗日志,在此基础上优化代码提升速度<a id="more"></a></p><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>通过正则提取日志中的有用信息,存入 DataFrame中进行分析</p><h1 id="公共代码"><a href="#公共代码" class="headerlink" title="公共代码"></a>公共代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">regex = re.compile(<span class="string">r"\[(.*?)\].*?\[(.*?)\].*?\[(.*?)\].*?\[(.*?)\].*?\[(.*?)\].*?\[(.*?)\].*?\[(.*?)\].*?(\&#123;.*\&#125;)"</span>)</span><br></pre></td></tr></table></figure><h1 id="优化前"><a href="#优化前" class="headerlink" title="优化前"></a>优化前</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">start = time.time()</span><br><span class="line">df_interface = pd.DataFrame()</span><br><span class="line">interface_dir_path = <span class="string">'/Users/zhangjun/PycharmProjects/LogAnalysis/data/gateway_hour/interface'</span></span><br><span class="line"></span><br><span class="line">files = os.listdir(interface_dir_path)</span><br><span class="line"><span class="comment"># tempList = []</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">    <span class="keyword">with</span> open(interface_dir_path + <span class="string">'/'</span> + file) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            matches = regex.search(line)</span><br><span class="line">            <span class="keyword">if</span> matches:</span><br><span class="line">                LOG_TIME = matches.group(<span class="number">1</span>)</span><br><span class="line">                LOG_UNIQUE_ID = matches.group(<span class="number">4</span>)</span><br><span class="line">                api_list = LOG_UNIQUE_ID.split(<span class="string">'_'</span>)[<span class="number">2</span>:]</span><br><span class="line">                LOG_API = <span class="string">'_'</span>.join(api_list)</span><br><span class="line">                LOG_PROTOCOL = matches.group(<span class="number">6</span>)</span><br><span class="line">                LOG_TYPE = matches.group(<span class="number">7</span>)</span><br><span class="line">                LOG_JSON_CONTENG = matches.group(<span class="number">8</span>)</span><br><span class="line">                result = &#123;<span class="string">'time'</span>: LOG_TIME, <span class="string">'unique_id'</span>: LOG_UNIQUE_ID, <span class="string">'protocol'</span>: LOG_PROTOCOL, <span class="string">'type'</span>: LOG_TYPE,</span><br><span class="line">                          <span class="string">'api'</span>: LOG_API&#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> LOG_API == <span class="string">'mbp-gateway_operator_v1_login'</span> <span class="keyword">and</span> LOG_TYPE == <span class="string">'request'</span>:</span><br><span class="line">                    request_json = json.loads(LOG_JSON_CONTENG)</span><br><span class="line">                    request_header = request_json[<span class="string">'requestHeader'</span>]</span><br><span class="line">                    request_params = request_json[<span class="string">'params'</span>]</span><br><span class="line">                    result.update(request_header)</span><br><span class="line">                    result.update(request_params)</span><br><span class="line">                    s = pd.Series(result)</span><br><span class="line">                    <span class="comment"># tempList.append(s)</span></span><br><span class="line">                    df_interface = df_interface.append(s, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    print(file + <span class="string">"清理完毕添加到 DataFrame"</span>)</span><br><span class="line"><span class="comment"># df_interface = pd.DataFrame(tempList)</span></span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">'interface清理读取到 DF,耗时'</span> + str(end - start))</span><br></pre></td></tr></table></figure><p>耗时:13.6s</p><h1 id="第一次优化"><a href="#第一次优化" class="headerlink" title="第一次优化"></a>第一次优化</h1><p>有原来的<code>df.append</code>改成 <code>list.append</code>.带来约四倍提升.非常有效,在另外一个处理脚本提高了8倍速度.非常感人.推荐这种优化.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">start = time.time()</span><br><span class="line">df_interface = pd.DataFrame()</span><br><span class="line">interface_dir_path = <span class="string">'/Users/zhangjun/PycharmProjects/LogAnalysis/data/gateway_hour/interface'</span></span><br><span class="line"></span><br><span class="line">files = os.listdir(interface_dir_path)</span><br><span class="line">tempList = []</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">    <span class="keyword">with</span> open(interface_dir_path + <span class="string">'/'</span> + file) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            matches = regex.search(line)</span><br><span class="line">            <span class="keyword">if</span> matches:</span><br><span class="line">                LOG_TIME = matches.group(<span class="number">1</span>)</span><br><span class="line">                LOG_UNIQUE_ID = matches.group(<span class="number">4</span>)</span><br><span class="line">                api_list = LOG_UNIQUE_ID.split(<span class="string">'_'</span>)[<span class="number">2</span>:]</span><br><span class="line">                LOG_API = <span class="string">'_'</span>.join(api_list)</span><br><span class="line">                LOG_PROTOCOL = matches.group(<span class="number">6</span>)</span><br><span class="line">                LOG_TYPE = matches.group(<span class="number">7</span>)</span><br><span class="line">                LOG_JSON_CONTENG = matches.group(<span class="number">8</span>)</span><br><span class="line">                result = &#123;<span class="string">'time'</span>: LOG_TIME, <span class="string">'unique_id'</span>: LOG_UNIQUE_ID, <span class="string">'protocol'</span>: LOG_PROTOCOL, <span class="string">'type'</span>: LOG_TYPE,</span><br><span class="line">                          <span class="string">'api'</span>: LOG_API&#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> LOG_API == <span class="string">'mbp-gateway_operator_v1_login'</span> <span class="keyword">and</span> LOG_TYPE == <span class="string">'request'</span>:</span><br><span class="line">                    request_json = json.loads(LOG_JSON_CONTENG)</span><br><span class="line">                    request_header = request_json[<span class="string">'requestHeader'</span>]</span><br><span class="line">                    request_params = request_json[<span class="string">'params'</span>]</span><br><span class="line">                    result.update(request_header)</span><br><span class="line">                    result.update(request_params)</span><br><span class="line">                    s = pd.Series(result)</span><br><span class="line">                    tempList.append(s)</span><br><span class="line">                    <span class="comment"># df_interface = df_interface.append(s, ignore_index=True)</span></span><br><span class="line">    print(file + <span class="string">"清理完毕添加到 DataFrame"</span>)</span><br><span class="line">df_interface = pd.DataFrame(tempList)</span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">'interface清理读取到 DF,耗时'</span> + str(end - start))</span><br></pre></td></tr></table></figure></p><p>耗时:3.7s</p><h1 id="第二次优化"><a href="#第二次优化" class="headerlink" title="第二次优化"></a>第二次优化</h1><ol><li>先将所有分散的文件聚合成一个文件<code>cat * &gt; interface.log</code></li><li>然后在在第一次优化的基础上直接处理这个一个文件,而不是处理多个小文件</li></ol><p>思路:本意是想在 IO 这块提升速度.一个文件只会有两次 IO, 而多个小文件,这 IO 操作太频繁影响处理速度.<br>实验证明这种方法意义不大.首先<code>cat</code>操作本身需要时间,在这第二步执行结果发现提升非常有限.<br><strong>暂时结论</strong>是不推荐这种方法</p><h2 id="第三个优化"><a href="#第三个优化" class="headerlink" title="第三个优化"></a>第三个优化</h2><p>在做正则匹配的时候,加一个字符串判断,而不是每行都做正则匹配,当文本很长的时候,正则匹配非常耗时.<br>而用 python 原生的<code>in</code>来做判断可以提速,非常明显.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">'[request]'</span> <span class="keyword">in</span> line:</span><br><span class="line">    request_match = regrex_request.search(line)</span><br><span class="line"><span class="keyword">if</span> <span class="string">'[response]'</span> <span class="keyword">in</span> line:</span><br><span class="line">    response_match = regrex_response.search(line)</span><br><span class="line"><span class="keyword">if</span> <span class="string">'[all_cost]'</span> <span class="keyword">in</span> line:</span><br><span class="line">    all_cost_match = regrex_all_cost.search(line)</span><br><span class="line"><span class="keyword">if</span> <span class="string">'send][cost]'</span> <span class="keyword">in</span> line:</span><br><span class="line">    channel_cost_match = regrex_channel_cost.search(line)</span><br></pre></td></tr></table></figure></p><h2 id="第四次优化"><a href="#第四次优化" class="headerlink" title="第四次优化"></a>第四次优化</h2><p>多进程处理.一般 python代码都只使用一个 CPU. 利用<code>ProcessPoolExecutor</code>可以轻松实现多进程处理,非常适合计算型任务(Wall Time ≈ CPU Total Time).关于 IO 密集和计算密集参考<a href="https://zjsnowman.com/2017/09/25/jupyter-%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/#%E9%AD%94%E6%B3%95%E5%91%BD%E4%BB%A4">Python IO/计算密集</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"><span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">    image_files = glob.glob(<span class="string">"*.jpg"</span>)</span><br><span class="line">    <span class="keyword">for</span> image_file, thumbnail_file <span class="keyword">in</span> zip(image_files, executor.map (make_image_thumbnail, image_files)):  </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> globimport osfrom PIL </span><br><span class="line"><span class="keyword">import</span> Image</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_image_thumbnail</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># 缩略图会被命名为"&lt;original_filename&gt;_thumbnail.jpg"</span></span><br><span class="line">    base_filename, file_extension = os.path.splitext(filename)</span><br><span class="line">    thumbnail_filename = <span class="string">f"<span class="subst">&#123;base_filename&#125;</span>_thumbnail<span class="subst">&#123;file_extension&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建和保存缩略图</span></span><br><span class="line">    image = Image.open(filename)</span><br><span class="line">    image.thumbnail(size=(<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">    image.save(thumbnail_filename, <span class="string">"JPEG"</span>)    </span><br><span class="line">    <span class="keyword">return</span> thumbnail_filename<span class="comment"># 循环文件夹中所有JPEG图像，为每张图像创建缩略图</span></span><br></pre></td></tr></table></figure><p>上述方法非常适合下面的任务:</p><ul><li><p>从一堆XML，CSV和JSON文件中解析数据。</p></li><li><p>对大量图片数据做预处理，建立机器学习数据集。</p></li></ul><p><strong>这里总结一个处理上述任务的一个套路</strong></p><ol><li><p>首先获得你想处理的文件（或其它数据）的列表</p></li><li><p>写一个辅助函数，能够处理上述文件的单个数据</p></li><li><p>使用for循环调用辅助函数，处理每一个单个数据，一次一个。</p></li></ol><p>学习链接:<a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1551663000&amp;ver=1463&amp;signature=6Nu6FISE-fxdHgulsA4eVKDK-z48c9XWEo3ESnPGysSixYC29T7aDGEzEHVRrCcpma-f1jFKwOfqrMa7dYwEpg0YCIk9feqckoc5HbN30mi2jZ7T08g4-4Zj16dP-Nan&amp;new=1" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1551663000&amp;ver=1463&amp;signature=6Nu6FISE-fxdHgulsA4eVKDK-z48c9XWEo3ESnPGysSixYC29T7aDGEzEHVRrCcpma-f1jFKwOfqrMa7dYwEpg0YCIk9feqckoc5HbN30mi2jZ7T08g4-4Zj16dP-Nan&amp;new=1</a></p><h2 id="七个提升-Python性能的好习惯"><a href="#七个提升-Python性能的好习惯" class="headerlink" title="七个提升 Python性能的好习惯"></a>七个提升 Python性能的好习惯</h2><ul><li>使用局部变量</li><li>减少函数调用次数</li><li>采用映射替代条件查找</li><li>直接迭代序列元素</li><li>采用生成器表达式替代列表解析</li><li>先编译后调用</li><li>模块编程习惯</li></ul><p><a href="https://mp.weixin.qq.com/s/lH_B3BFBrmzuKZp7djoxOA" target="_blank" rel="noopener">七个提升Python 性能的好习惯</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过 Python+ Pandas +regrex清洗日志,在此基础上优化代码提升速度
    
    </summary>
    
    
    
      <category term="数据分析" scheme="http://zjsnowman.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Python优化" scheme="http://zjsnowman.com/tags/Python%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>Linux 基本操作</title>
    <link href="http://zjsnowman.com/2018/04/28/Linux-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <id>http://zjsnowman.com/2018/04/28/Linux-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</id>
    <published>2018-04-28T02:13:48.000Z</published>
    <updated>2019-10-21T02:55:51.576Z</updated>
    
    <content type="html"><![CDATA[<p>这里以生产上主流的 Centos 为目标进行学习<a id="more"></a></p><h1 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h1><h2 id="用户和用户组"><a href="#用户和用户组" class="headerlink" title="用户和用户组"></a>用户和用户组</h2><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-043912.jpg" alt><br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-08-24-043831.jpg" alt></p><p>最早是没有 <code>gshadow</code>和 <code>shadow</code>两个文件的,这两个分别是存放组密码和用户密码的文件.早起组和用户<br>密码都是分别放在 <code>group</code>和<code>password</code>一起的,但是由于这两个文件经常需要被读取来判断当期那用户所属<br>的权限和组权限.所以权限不能太严格.处于安全的考虑,就把密码信息单独拿出来放到<code>gshadow</code>和<code>shadow</code><br>中.</p><h1 id="资源查看"><a href="#资源查看" class="headerlink" title="资源查看"></a>资源查看</h1><h2 id="查看内存"><a href="#查看内存" class="headerlink" title="查看内存"></a>查看内存</h2><p><code>free -m</code> 以 MB 的方式查看内存使用情况</p><h2 id="查看-CPU-情况"><a href="#查看-CPU-情况" class="headerlink" title="查看 CPU 情况"></a>查看 CPU 情况</h2><p><code>cat /proc/cpuinfo</code> 查看 CPU情况</p><h1 id="权限管理-1"><a href="#权限管理-1" class="headerlink" title="权限管理"></a>权限管理</h1><h2 id="更改文件-文件夹所属用户和用户组-需要-root-权限执行该命令"><a href="#更改文件-文件夹所属用户和用户组-需要-root-权限执行该命令" class="headerlink" title="更改文件,文件夹所属用户和用户组,需要 root 权限执行该命令"></a>更改文件,文件夹所属用户和用户组,需要 root 权限执行该命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Change user and group ownership of files and folders.</span><br><span class="line"></span><br><span class="line">- Change the owner user of a file/folder:</span><br><span class="line">    chown user path/to/file</span><br><span class="line"></span><br><span class="line">- Change the owner user and group of a file/folder:</span><br><span class="line">    chown user:group path/to/file</span><br><span class="line"></span><br><span class="line">- Recursively change the owner of a folder and its contents:</span><br><span class="line">    chown -R user path/to/folder</span><br><span class="line"></span><br><span class="line">- Change the owner of a symbolic link:</span><br><span class="line">    chown -h user path/to/symlink</span><br><span class="line"></span><br><span class="line">- Change the owner of a file/folder to match a reference file:</span><br><span class="line">    chown --reference=path/to/reference_file path/to/file</span><br></pre></td></tr></table></figure><h2 id="更改文件权限"><a href="#更改文件权限" class="headerlink" title="更改文件权限"></a>更改文件权限</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Change the access permissions of a file or directory.</span><br><span class="line"></span><br><span class="line">- Give the [u]ser who owns a file the right to e[x]ecute it:</span><br><span class="line">    chmod u+x file</span><br><span class="line"></span><br><span class="line">- Give the user rights to [r]ead and [w]rite to a file/directory:</span><br><span class="line">    chmod u+rw file</span><br><span class="line"></span><br><span class="line">- Remove executable rights from the [g]roup:</span><br><span class="line">    chmod g-x file</span><br><span class="line"></span><br><span class="line">- Give [a]ll users rights to read and execute:</span><br><span class="line">    chmod a+rx file</span><br><span class="line"></span><br><span class="line">- Give [o]thers (not in the file owner&apos;s group) the same rights as the group:</span><br><span class="line">    chmod o=g file</span><br><span class="line"></span><br><span class="line">- Change permissions recursively giving [g]roup and [o]thers the abililty to [w]rite:</span><br><span class="line">    chmod -R g+w,o+w directory</span><br></pre></td></tr></table></figure><h1 id="定时任务-Crontab"><a href="#定时任务-Crontab" class="headerlink" title="定时任务 Crontab"></a>定时任务 Crontab</h1><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>参考 <code>tldr crontab</code></p><h2 id="使用日期时间命名重定向文件"><a href="#使用日期时间命名重定向文件" class="headerlink" title="使用日期时间命名重定向文件"></a>使用日期时间命名重定向文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 12 * * * php /Users/fdipzone/test.php &gt;&gt; "/Users/fdipzone/$(date +"%Y-%m-%d").log" 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p><code>2&gt;&amp;1</code> 表示把标准错误输出重定向到与标准输出一致，即test.log</p><p><code>&gt;&gt;</code>表示追加<br><a href="https://blog.csdn.net/fdipzone/article/details/51778543" target="_blank" rel="noopener">参考这篇博文</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里以生产上主流的 Centos 为目标进行学习
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>pandas 和 Numpy 学习备注</title>
    <link href="http://zjsnowman.com/2018/04/11/pandas-%E5%92%8C-Numpy-%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/"/>
    <id>http://zjsnowman.com/2018/04/11/pandas-%E5%92%8C-Numpy-%E5%AD%A6%E4%B9%A0%E5%A4%87%E6%B3%A8/</id>
    <published>2018-04-11T09:30:43.000Z</published>
    <updated>2019-10-21T02:55:51.579Z</updated>
    
    <content type="html"><![CDATA[<p>pandas 和 numpy 使用备注<a id="more"></a></p><h1 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h1><blockquote><p>精通面向数组的编程和思维方式成为 Python 科学计算牛人的一大关键步骤</p></blockquote><p>用数组表达式代替循环的做法,通常被称为矢量化</p><p>Numpy.ndarray.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data.shape  <span class="comment"># 显示 array 的大小</span></span><br><span class="line">data.dtype  <span class="comment"># 显示 array 的数据类型, array 所有的数据类型都必须是一样的</span></span><br><span class="line">data.ndim  <span class="comment"># 显示数据维度,一维还是二维还是多维</span></span><br><span class="line">data.size  <span class="comment">#显示数据量的多少</span></span><br></pre></td></tr></table></figure><p><code>np.arange()</code>是Python 内置<code>range()</code>的数组版</p><h2 id="ndarry-的数据类型"><a href="#ndarry-的数据类型" class="headerlink" title="ndarry 的数据类型"></a>ndarry 的数据类型</h2><p>dtype 是 Numpy 灵活和强大的原因之一<br><strong>调用astype 无论如何都会创建一个新的数组,即使新的 dtype 跟老的 dtype 相同也是如此</strong></p><h2 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h2><h3 id="数组与数组之间"><a href="#数组与数组之间" class="headerlink" title="数组与数组之间"></a>数组与数组之间</h3><ul><li>大小相同的数组之间的任何算术运算都会将运算应用到元素级</li><li>数组与标量的算术运算也会将那个标量值传播到各个元素</li></ul><h2 id="切片操作"><a href="#切片操作" class="headerlink" title="切片操作"></a>切片操作</h2><ul><li>Python 切片<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In:</span><br><span class="line">  A=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">  Ahat=A[<span class="number">2</span>:<span class="number">4</span>]  <span class="comment">#1</span></span><br><span class="line">  Ahat[<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">  Ahat</span><br><span class="line">Out:</span><br><span class="line">  [<span class="number">1</span>, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">In:</span><br><span class="line">  A</span><br><span class="line">Out:</span><br><span class="line">  [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure></li></ul><p>这里<code>1</code>这个地方对于 python 来说是一个复制的操作,所以对 Ahat 做的所有操作并不会影响 A</p><ul><li>Numpy 切片<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In:</span><br><span class="line">  arr = np.arange(<span class="number">10</span>)</span><br><span class="line">  arr[<span class="number">5</span>:<span class="number">8</span>] = <span class="number">12</span></span><br><span class="line">  arr</span><br><span class="line">Out:</span><br><span class="line">  array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">12</span>, <span class="number">12</span>, <span class="number">12</span>,  <span class="number">8</span>,  <span class="number">9</span>])</span><br><span class="line">In:</span><br><span class="line">  arr_slice = arr[<span class="number">5</span>:<span class="number">8</span>]  <span class="comment">#2 </span></span><br><span class="line">  arr_slice[:] = <span class="number">64</span></span><br><span class="line">  arr</span><br><span class="line">Out:</span><br><span class="line">  array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">64</span>,  <span class="number">8</span>,  <span class="number">9</span>])</span><br></pre></td></tr></table></figure></li></ul><p>在 Numpy 中这不是一个复制操作,相当于一个指针,你对 arr_slice的所有操作都会传播到原始数据.如果要执行<br>复制才做需要调用<code>.copy()</code>函数.这么设计的目的是因为 Numpy 设计师为了处理大数据.如果复制来复制去会影响<br>性能和内存.同理在 DataFrame中如果需要对切片数据赋值的话也是会影响到原始数据的,如果不希望这样的话也需要执行<code>.copy()</code>操作.在<code>#2</code>这个地方 <code>arr_slice = arr[5:8].copy()</code></p><h2 id="numpy-的复制与视图"><a href="#numpy-的复制与视图" class="headerlink" title="numpy 的复制与视图"></a>numpy 的复制与视图</h2><p>复制 - 花式索引,布尔索引</p><p>视图 - 切片,元素索引,转置</p><h2 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h2><ul><li><code>arange</code></li><li><code>linspace</code>  和 arange 的区别是参数包括 stop,且第三个参数不是步长,而是生成数组元素的数量</li><li><code>random</code><br>这里如果不指定 seed 的话,每次生成的随机矩阵都不一样.如果需要每次生成的随机矩阵一样的话,需要手动指定随机种子.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">24</span>)</span><br><span class="line">np.random.randint(<span class="number">1</span>,<span class="number">10</span>,size=(<span class="number">2</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure></li></ul><p>这样的话每次生成的随机矩阵就是一样的,方便调试算法.如果希望每次生成的矩阵都不一样,就不显示指定随机种子即可<br>该模块常用的三个方法分别是<code>random,randint,normal</code> .分别生成浮点数,整数,以及正态分布的随机数<br>还有个有意思的函数<code>np.random.shuffle(x)</code>可以对 x 的元素进行打乱. shuffle(洗牌)</p><h2 id="Numpy矩阵访问方法"><a href="#Numpy矩阵访问方法" class="headerlink" title="Numpy矩阵访问方法"></a>Numpy矩阵访问方法</h2><p>Numpy 专门为矩阵发明了一种检索语法 <code>data[row,column]</code>,这种语法是专门针对矩阵进行优化,当然在具体索引某个具体的值的时候使用 <code>data[row][column]</code>也是可以的.但是前者效率更高.而且前者支持切片语法,能够很方便的截取部分矩阵.比如 <code>data[:2,:3]</code>表示截取前两行和前三列.而用 <code>data[2][3]</code>则不会得到我们想要的数据,这个具体执行一遍就清楚了.</p><p><strong>这里结论就是同意用Numpy 提供的 <code>data[row,column]</code>语法来访问数据</strong></p><h2 id="合并与分割"><a href="#合并与分割" class="headerlink" title="合并与分割"></a>合并与分割</h2><ul><li><code>np.concatenate()</code> 通用合并方法,需要制定 axis</li><li><code>np.vstack()</code>  垂直合并,而且容错性更好</li><li><p><code>np.hstack()</code> 水平合并</p></li><li><p><code>np.split()</code> 分割通用方法</p></li><li><code>np.vsplit()</code>  垂直分割</li><li><code>np.hsplit()</code> 水平分割</li></ul><h2 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h2><p>np 的聚合函数比python 原生的效率要高.</p><ul><li><code>np.sum()</code></li><li><code>np.min()  np.max(),np.median(),np.mean(),np.percentile()</code></li></ul><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>- <code>np.argmax()</code><br>其他类似,找到对应的索引</p><h2 id="Fancy-Indexing"><a href="#Fancy-Indexing" class="headerlink" title="Fancy Indexing"></a>Fancy Indexing</h2><ul><li><code>np.count_nonzero(x)</code> 计算 x 中非零元素的个数,方便统计布尔数组中 True 的个数,当然也可以使用 <code>sum()</code></li><li><code>np.any(x==0) VS np.all(x==0)</code> 前者只要 x 有任何一个满足条件就会返回 True,后者需要 x 全部满足条件才可以  </li></ul><p><strong>机器学习算法中,接受的 一般都是一个 numpy 数组,而 pandas 更多是在 numpy 上封装了很多灵活的方法,可以很方便我们用来对数据预处理,处理完的数据最好还是需要转成 numpy 数组的.所以理解 numpy 非常有必要</strong></p><h1 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h1><h2 id="Series-和-DataFrame"><a href="#Series-和-DataFrame" class="headerlink" title="Series 和 DataFrame"></a>Series 和 DataFrame</h2><p><a href="http://pandas.pydata.org/pandas-docs/stable/dsintro.html#name-attribute" target="_blank" rel="noopener">各种初始化方法官方文档</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">6</span>]: dates = pd.date_range(<span class="string">'20130101'</span>, periods=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: dates</span><br><span class="line">Out[<span class="number">7</span>]:</span><br><span class="line">DatetimeIndex([<span class="string">'2013-01-01'</span>, <span class="string">'2013-01-02'</span>, <span class="string">'2013-01-03'</span>, <span class="string">'2013-01-04'</span>,</span><br><span class="line">               <span class="string">'2013-01-05'</span>, <span class="string">'2013-01-06'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: df = pd.DataFrame(np.random.randn(<span class="number">6</span>,<span class="number">4</span>), index=dates, columns=list(<span class="string">'ABCD'</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: df</span><br><span class="line">Out[<span class="number">9</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span></span><br></pre></td></tr></table></figure><p>DataFrame 是有数据, index(label)和 columns 三部分组成</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">16</span>]: df.index</span><br><span class="line">Out[<span class="number">16</span>]:</span><br><span class="line">DatetimeIndex([<span class="string">'2013-01-01'</span>, <span class="string">'2013-01-02'</span>, <span class="string">'2013-01-03'</span>, <span class="string">'2013-01-04'</span>,</span><br><span class="line">               <span class="string">'2013-01-05'</span>, <span class="string">'2013-01-06'</span>],</span><br><span class="line">              dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: df.columns</span><br><span class="line">Out[<span class="number">17</span>]: Index([<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>], dtype=<span class="string">'object'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: df.values</span><br><span class="line">Out[<span class="number">18</span>]:</span><br><span class="line">array([[ <span class="number">0.4691</span>, <span class="number">-0.2829</span>, <span class="number">-1.5091</span>, <span class="number">-1.1356</span>],</span><br><span class="line">       [ <span class="number">1.2121</span>, <span class="number">-0.1732</span>,  <span class="number">0.1192</span>, <span class="number">-1.0442</span>],</span><br><span class="line">       [<span class="number">-0.8618</span>, <span class="number">-2.1046</span>, <span class="number">-0.4949</span>,  <span class="number">1.0718</span>],</span><br><span class="line">       [ <span class="number">0.7216</span>, <span class="number">-0.7068</span>, <span class="number">-1.0396</span>,  <span class="number">0.2719</span>],</span><br><span class="line">       [<span class="number">-0.425</span> ,  <span class="number">0.567</span> ,  <span class="number">0.2762</span>, <span class="number">-1.0874</span>],</span><br><span class="line">       [<span class="number">-0.6737</span>,  <span class="number">0.1136</span>, <span class="number">-1.4784</span>,  <span class="number">0.525</span> ]])</span><br></pre></td></tr></table></figure><p>通过上面三个方法,分别查看 DF 的数据, index和 columns</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">41</span>]: df2 = df.copy()</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: df2[<span class="string">'E'</span>] = [<span class="string">'one'</span>, <span class="string">'one'</span>,<span class="string">'two'</span>,<span class="string">'three'</span>,<span class="string">'four'</span>,<span class="string">'three'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: df2</span><br><span class="line">Out[<span class="number">43</span>]:</span><br><span class="line">                   A         B         C         D      E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="number">0.469112</span> <span class="number">-0.282863</span> <span class="number">-1.509059</span> <span class="number">-1.135632</span>    one</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">1.212112</span> <span class="number">-0.173215</span>  <span class="number">0.119209</span> <span class="number">-1.044236</span>    one</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span>    two</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">0.721555</span> <span class="number">-0.706771</span> <span class="number">-1.039575</span>  <span class="number">0.271860</span>  three</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span>   four</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span> <span class="number">-0.673690</span>  <span class="number">0.113648</span> <span class="number">-1.478427</span>  <span class="number">0.524988</span>  three</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: df2[df2[<span class="string">'E'</span>].isin([<span class="string">'two'</span>,<span class="string">'four'</span>])]</span><br><span class="line">Out[<span class="number">44</span>]:</span><br><span class="line">                   A         B         C         D     E</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.861849</span> <span class="number">-2.104569</span> <span class="number">-0.494929</span>  <span class="number">1.071804</span>   two</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-0.424972</span>  <span class="number">0.567020</span>  <span class="number">0.276232</span> <span class="number">-1.087401</span>  four</span><br></pre></td></tr></table></figure><p>注意这里的<code>df2=df.copy()</code>.如果不用 <code>copy()</code>函数,对 df2做的所有操作都会反映到 df上</p><h2 id="常用函数-1"><a href="#常用函数-1" class="headerlink" title="常用函数"></a>常用函数</h2><ul><li><code>Series.value_counts()</code> 统计该 series 下的 item 出现频次.</li><li><code>Series.unique()</code>  返回该 series去重后的值,可以和<code>value_counts</code>配合使用</li><li><code>Series.idxmax(axis=0, skipna=True, *args, **kwargs)</code> 返回该列最大值的index</li><li><code>Series.agg(func, axis=0, *args, **kwargs)</code> 对一个 series 的每行或者每列执行多个函数操作</li><li><code>DataFrame.set_index(keys, drop=True, append=False, - inplace=False,verify_integrity=False)</code> 用 DF 的某个列来作为 index</li><li><code>DataFrame.rename(mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None)</code> DF 重命名index,columns</li><li><code>Series.dropna(axis=0, inplace=False, **kwargs)</code> 丢掉缺失的行.<strong>空串不是 NA,None是 NA</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ser = pd.Series([np.NaN, <span class="number">2</span>, pd.NaT, <span class="string">''</span>, <span class="literal">None</span>, <span class="string">'I stay'</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ser</span><br><span class="line"><span class="number">0</span>       NaN</span><br><span class="line"><span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">2</span>       NaT</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span>      <span class="literal">None</span></span><br><span class="line"><span class="number">5</span>    I stay</span><br><span class="line">dtype: object</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ser.dropna()</span><br><span class="line"><span class="number">1</span>         <span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span>    I stay</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure></li></ul><h2 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h2><h3 id="计算指标-哑变量-Dummy-Variables"><a href="#计算指标-哑变量-Dummy-Variables" class="headerlink" title="计算指标/哑变量(Dummy Variables)"></a>计算指标/哑变量(Dummy Variables)</h3><p>参考书籍第七章-数据转换</p><h2 id="透视表和交叉表"><a href="#透视表和交叉表" class="headerlink" title="透视表和交叉表"></a>透视表和交叉表</h2><p><a href="一文看懂透视表pivot_table">一文看懂透视表pivot_table</a><br>书籍第九章透视表和交叉表<br>交叉表</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;pandas 和 numpy 使用备注
    
    </summary>
    
    
    
      <category term="数据分析" scheme="http://zjsnowman.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
</feed>
