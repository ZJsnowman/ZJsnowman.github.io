<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="数据分析,">





  <link rel="alternate" href="/atom.xml" title="看见什么吃什么" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2">






<meta name="description" content="机器学习备注">
<meta name="keywords" content="数据分析">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习">
<meta property="og:url" content="http://zjsnowman.com/2018/11/27/机器学习备注/index.html">
<meta property="og:site_name" content="看见什么吃什么">
<meta property="og:description" content="机器学习备注">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://zjsnowman.com/images/machineLearning.png">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79gy1fqjaoeg0euj31c00s6q87.jpg">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-20-120435.png">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-25-085115.png">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-26-071311.png">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-26-071205.png">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNc79gy1fqjaofthnxj31kw0wmdnh.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNc79gy1fqjaogtziwj31kw0sq45m.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNc79gy1fqjaohwj5oj31kw0vw0z3.jpg">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-09-010656.png">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-06-092302.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNc79gy1fqjaoilapaj31kw0vn41c.jpg">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-v09-09-012650.png">
<meta property="og:image" content="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-09-012941.png">
<meta property="og:updated_time" content="2019-10-21T02:55:51.582Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习">
<meta name="twitter:description" content="机器学习备注">
<meta name="twitter:image" content="http://zjsnowman.com/images/machineLearning.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'AEDNVYBRXD',
      apiKey: '8b0fd63b8531c6673fc8ec50b80429ef',
      indexName: 'prod_blog',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zjsnowman.com/2018/11/27/机器学习备注/">





  <title>机器学习 | 看见什么吃什么</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-104303218-1', 'auto');
  ga('send', 'pageview');
</script>











</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">看见什么吃什么</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://zjsnowman.com/2018/11/27/机器学习备注/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张俊">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="看见什么吃什么">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-27T17:20:02+08:00">
                2018-11-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/11/27/机器学习备注/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/11/27/机器学习备注/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/11/27/机器学习备注/" class="leancloud_visitors" data-flag-title="机器学习">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="/images/machineLearning.png" alt><br>机器学习备注<a id="more"></a></p>
<h1 id="Naive-Bayes-贝叶斯推断"><a href="#Naive-Bayes-贝叶斯推断" class="headerlink" title="Naive Bayes(贝叶斯推断)"></a>Naive Bayes(贝叶斯推断)</h1><p><a href="http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html" target="_blank" rel="noopener">讲解贝叶斯基本算法原理</a></p>
<h2 id="朴素贝叶斯为啥朴素"><a href="#朴素贝叶斯为啥朴素" class="headerlink" title="朴素贝叶斯为啥朴素"></a>朴素贝叶斯为啥朴素</h2><p>因为贝叶斯算法并没有考虑事情发生的顺序.<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fqjaoeg0euj31c00s6q87.jpg" alt></p>
<h2 id="朴素贝叶斯的优势和劣势"><a href="#朴素贝叶斯的优势和劣势" class="headerlink" title="朴素贝叶斯的优势和劣势"></a>朴素贝叶斯的优势和劣势</h2><ul>
<li>优势</li>
</ul>
<p>这种算法非常适合文本分类。在处理文本时，常见的做法是将每个单词看作一个特征，这样就会有大量的特征。此算法的相对简单性和朴素贝叶斯独立特征的这一假设，使其能够出色完成文本的分类</p>
<ul>
<li>劣势</li>
</ul>
<p>当事情的顺序很重要的时候,就不行.比如早起 google芝加哥公牛的时候.就会出现一些芝加哥的介绍或者公牛的照片.但是明显芝加哥公牛有其他的意思.这个时候贝叶斯就不是很管用的</p>
<ul>
<li>总结</li>
</ul>
<p>如何避免这些,我们采用的监督式学习.也就有试验和测试数据.通过测试就能够知道算法是否有效</p>
<h1 id="SVM-支持向量机"><a href="#SVM-支持向量机" class="headerlink" title="SVM(支持向量机)"></a>SVM(支持向量机)</h1><p>核心概念- 间隔(margin)  </p>
<ul>
<li>支持向量机的内部原理是最大程度提高结果稳健性</li>
<li>正确分类标签作为首要考虑,然后对间隔进行最大化.也就是说要在分类正确的前提下对间隔最大化</li>
<li>SVM 可以忽略异常值,然后使间隔最大化</li>
</ul>
<p>SVM 不适合处理海量数据,训练时间太慢了<br>噪声过多情况下,类严重重叠,边界不明显也不适合 SVM. 可以考虑用 Navie Bayes</p>
<p><a href="http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-33-SVM/" target="_blank" rel="noopener">参考 udacity 学习笔记</a></p>
<h1 id="Decision-Trees-决策树"><a href="#Decision-Trees-决策树" class="headerlink" title="Decision Trees (决策树)"></a>Decision Trees (决策树)</h1><ul>
<li>非参数学习方法(类似KNN 容易过拟合)</li>
<li>可以解决分类/回归问题</li>
<li>天然可以解决多分类问题</li>
<li>具备非常好的解释性</li>
</ul>
<h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p><a href="http://www.ruanyifeng.com/blog/2014/09/information-entropy.html" target="_blank" rel="noopener">信息熵的定义</a><br>按照信息熵减小的方向去确定分类边界</p>
<h2 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a>基尼系数</h2><p>类似信息熵<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-20-120435.png" alt></p>
<h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>容易过拟合<br>可以通过剪枝来降低模型复杂度,解决过拟合<br><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" target="_blank" rel="noopener">决策树理解,讲的不错</a><br><a href="http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-34-DecisionTrees/" target="_blank" rel="noopener">udacity 学习笔记</a></p>
<h1 id="k-nearest-neighbors"><a href="#k-nearest-neighbors" class="headerlink" title="k-nearest neighbors"></a>k-nearest neighbors</h1><p><a href="https://zhuanlan.zhihu.com/p/25994179" target="_blank" rel="noopener">查考</a></p>
<p><a href="http://road2autodrive.info/2018/01/16/Uda-DataAnalysis-39-cluster/" target="_blank" rel="noopener">udacity学习笔记</a></p>
<ul>
<li>K近邻算法比较特殊,可以认为是没有模型的算法,为了和其他算法统一,也可以认为训练数据集就是模型本身</li>
</ul>
<h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><p><a href="http://www.cnblogs.com/pinard/p/6131423.html" target="_blank" rel="noopener">参考</a></p>
<ul>
<li>hard </li>
<li>soft 带权重的hard模式</li>
</ul>
<h2 id="Bagging-and-随机森林"><a href="#Bagging-and-随机森林" class="headerlink" title="Bagging and 随机森林"></a>Bagging and 随机森林</h2><p>### 如何构建不同的子模型<br>对样本和特征进行随机选择<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-25-085115.png" alt></p>
<p>通俗来说就是对行级别和列级别抽样,都抽样就是Patches.</p>
<ul>
<li>Bagging(样本有放回随机抽样),统计学上叫Bootstrap.不放回抽样叫Pasting</li>
<li>Random Subspace(特征随机抽样)  图像识别领域用的比较多,特征比较多</li>
<li>Random Patches (即针对样本又针对特征) ,代表就是随机深林</li>
</ul>
<h2 id="Ada-Boosting"><a href="#Ada-Boosting" class="headerlink" title="Ada Boosting"></a>Ada Boosting</h2><p>给上一个模型没有匹配到的数据更大的权值,然后重新拟合.最初的模型所有样本数据的权值是一样的<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-26-071311.png" alt></p>
<h2 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h2><p>对上一个模型没有匹配的样本建立一个新的模型,最后把所有模型叠加起来<br><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-10-26-071205.png" alt></p>
<h1 id="准确度与训练集大小的关系"><a href="#准确度与训练集大小的关系" class="headerlink" title="准确度与训练集大小的关系"></a>准确度与训练集大小的关系</h1><p>更大的数据量要比经过精密调整的算法提供更好的结果,更大的数据能够取得更好的效果,这是<br>机器学习领域至理名言</p>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><ul>
<li>numberical 数值</li>
<li>categorical  分类</li>
<li>time series  时序</li>
<li>text  文字</li>
</ul>
<h1 id="判断离散还是连续"><a href="#判断离散还是连续" class="headerlink" title="判断离散还是连续"></a>判断离散还是连续</h1><p><strong>关注顺序</strong></p>
<p>有些不好判断的类型,可以关注数据之间的顺序,如果之间有强烈的关联性,则用连续性的分类器,否则就用离散性的分类器.比如,公司100个人, 工号从1-100,如果需要给他们分类,最好就用离散性的分类器,因为不同工号之前没有关联性</p>
<h1 id="回归-regression"><a href="#回归-regression" class="headerlink" title="回归(regression)"></a>回归(regression)</h1><h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>也叫<a href="https://www.wikiwand.com/zh-hans/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="noopener">最小平方法</a></p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>y=m*x+b 寻找系数和截距,通过最小化误差平方和</p>
<h3 id="线性回归误差"><a href="#线性回归误差" class="headerlink" title="线性回归误差"></a>线性回归误差</h3><p>误差=真实值-误差值 (注意存在正负值)<br><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fqjaofthnxj31kw0wmdnh.jpg" alt><br>通过上图,可以看出为啥不用误差绝对值的和而是用平方和的原因.用误差绝对值的和会存在多条线,<br>而用平方和就只会有一条</p>
<h3 id="误差平法和"><a href="#误差平法和" class="headerlink" title="误差平法和"></a>误差平法和</h3><p>判断拟合质量的标准</p>
<h4 id="最小化误差平方和的算法"><a href="#最小化误差平方和的算法" class="headerlink" title="最小化误差平方和的算法"></a>最小化误差平方和的算法</h4><ul>
<li>普通最小二乘法 ordinary least squares(sklearn LinearRegression中使用就是这种)</li>
<li>梯度下降 gradient descent</li>
</ul>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fqjaogtziwj31kw0sq45m.jpg" alt><br>当对不同数量的两个数据进行用最小误差平方和来评判算法好坏时会出现问题.拟合效果可能差不多,由于数量多的那个数据集天然误差平方和会大</p>
<h2 id="决定系数-R-suqre"><a href="#决定系数-R-suqre" class="headerlink" title="决定系数 R suqre"></a>决定系数 R suqre</h2><p><a href="https://www.wikiwand.com/zh-hans/%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0" target="_blank" rel="noopener">定义</a></p>
<p>决定系数的出现是为了解决上面误差平方和的缺陷.介于0-1之间,1最好,0最差.</p>
<h2 id="监督分类和回归的区别"><a href="#监督分类和回归的区别" class="headerlink" title="监督分类和回归的区别"></a>监督分类和回归的区别</h2><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fqjaohwj5oj31kw0vw0z3.jpg" alt></p>
<h2 id="多元线性回归-多变量回归-元理解成变量即可"><a href="#多元线性回归-多变量回归-元理解成变量即可" class="headerlink" title="多元线性回归(多变量回归,元理解成变量即可)"></a>多元线性回归(多变量回归,元理解成变量即可)</h2><p>多元回归和简单线性回归类似,只是变量增加而已.<br>y=x1+x2</p>
<h2 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h2><p>多项式回归处理方法和多元回归本质是也是一样的,只是把一元的多次作为一个特征来处理.对应<code>sklearn.preprocessing.PolynomialFeatures</code>.<br>y=x^2+x.这里把x^2 理解成一个特征即可,只是这个特征还是x这个元   .<br></p>
<h1 id="异常值"><a href="#异常值" class="headerlink" title="异常值"></a>异常值</h1><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><ul>
<li>传感器故障</li>
<li>数据输入错误</li>
</ul>
<h2 id="去除异常值的算法"><a href="#去除异常值的算法" class="headerlink" title="去除异常值的算法"></a>去除异常值的算法</h2><ol>
<li>回归</li>
<li>根据误差值排序,去除前10%</li>
<li>重新回归</li>
</ol>
<h1 id="Clustering-聚类"><a href="#Clustering-聚类" class="headerlink" title="Clustering(聚类)"></a>Clustering(聚类)</h1><h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><ol>
<li>将各个点分配到矩心</li>
<li>移动矩心,使各个点到矩心的距离最短<br>反复执行上面两个步骤<h2 id="K-means的局限"><a href="#K-means的局限" class="headerlink" title="K-means的局限"></a>K-means的局限</h2>依赖最初矩心所在的位置,不同的位置最终的结果可能会不同.<br>局部最小解</li>
</ol>
<h1 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h1><p>特征缩放的公式(x’-x_min)/(x_max-x_min)</p>
<h2 id="受此影响的机器学习算法"><a href="#受此影响的机器学习算法" class="headerlink" title="受此影响的机器学习算法"></a>受此影响的机器学习算法</h2><ul>
<li>使用 RBF 核函数的 SVM</li>
<li>K-means</li>
</ul>
<h1 id="涉及的一些中英对照"><a href="#涉及的一些中英对照" class="headerlink" title="涉及的一些中英对照"></a>涉及的一些中英对照</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">slope-&gt;斜率</span><br><span class="line">intercept-&gt;截距</span><br><span class="line">coefficient-&gt;系数</span><br></pre></td></tr></table></figure>
<h1 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h1><p>bag of words -词袋<br>stop words - 停止词<br>stemmer- 词干提取<br>TF-IDF<br>TF-Term Frequency<br>IDF-Inverse Document Frequency</p>
<p><a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html" target="_blank" rel="noopener">TF-IDF解释</a></p>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>为了防止过拟合采用的一种手段,在最小化sse(误差平方和) 的同时增加惩罚措施.<br>避免采用过多的特征维度.采用维度过少会导致高偏差(high bias,误差平方和较大).采用维度过度<br>会导致高方差(high varaiance,对测试数据集拟合不佳,不具有普遍性)</p>
<p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-09-010656.png" alt></p>
<ul>
<li>岭回归  在LinearRegression的基础上添加了L2正则项.可以理解为内置了线性模型</li>
</ul>
<p>[参考Sklearn Generaized Linear Models 这一章的前三节,具体公式也在其中.]<br>(<a href="http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression</a>)</p>
<h1 id="一些其他的点"><a href="#一些其他的点" class="headerlink" title="一些其他的点"></a>一些其他的点</h1><ul>
<li>过拟合就是在训练集上准确率非常高，而在测试集上准确率低</li>
</ul>
<h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><ul>
<li>一种用来降维的手段.是一种将输入特征转换为其主要特征的系统化方法</li>
<li>主成分的定义是数据中使方差最大话的方向(数据在上投影,使数据丢失的可能性降到最低)</li>
<li>主成分的上限是输入特征数量,当等于输入特征数量时就没有意义了,通常只会使用前面几个主成分</li>
<li>PCA最好在特征选择之前做.</li>
</ul>
<h2 id="帮助理解PCA"><a href="#帮助理解PCA" class="headerlink" title="帮助理解PCA"></a>帮助理解PCA</h2><p><a href="https://coding.imooc.com/learn/questiondetail/43110.html" target="_blank" rel="noopener">https://coding.imooc.com/learn/questiondetail/43110.html</a></p>
<h2 id="PCA的功能"><a href="#PCA的功能" class="headerlink" title="PCA的功能"></a>PCA的功能</h2><p>PCA可以起到降维的作用,这样主要是为了加快运行速度,另外也可以做可视化,讲数据在人类可以理解的二维或者三维上展示<br>另外一个主要的作用是降噪,在降维的同时将数据中包含的噪声减少.<br>这里需要注意的是,如果对于你的应用来说，保持特征语意很重要，又要减少特征量，是不建议使用PCA,可以试试LASSO.</p>
<h1 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h1><p><code>GridSearchCV</code>这个CV就是Cross Validation.<br>本质上为了更好的避免过拟合,如果没有验证数据集,训练出来的模型可能会对测试数据集过拟合.<br>所以通常将训练数据集分成训练数据集和验证数据集并配合K-Fold来对此验证取平均.这样来调模型的最佳参数.最后在用没有参与训练的测试基来检验模型的好坏</p>
<h1 id="方差偏差均衡"><a href="#方差偏差均衡" class="headerlink" title="方差偏差均衡"></a>方差偏差均衡</h1><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-06-092302.jpg" alt><br>通俗来说:偏差就是不准；方差就是不稳<br><a href="https://plushunter.github.io/2017/04/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8818%EF%BC%89%EF%BC%9A%E6%96%B9%E5%B7%AE%E5%81%8F%E5%B7%AE%E6%9D%83%E8%A1%A1%EF%BC%88Bias-Variance%20Tradeoff%EF%BC%89/" target="_blank" rel="noopener">参考</a></p>
<h1 id="如何解决过拟合问题"><a href="#如何解决过拟合问题" class="headerlink" title="如何解决过拟合问题"></a>如何解决过拟合问题</h1><ul>
<li><p>降低模型复杂度,比如多项式回归降低degree</p>
</li>
<li><p>正则化</p>
</li>
<li><p>增大样本数据</p>
</li>
<li><p>尝试化简，选择，提取更好的特征，所谓特征工程（特征不是越多越好！）</p>
</li>
<li><p>降噪,比如PCA</p>
</li>
<li><p>使用验证集避免针对测试数据集过拟合</p>
</li>
<li><p>尝试使用ensemble的方法（集成学习，见课程第十三章）</p>
</li>
</ul>
<h1 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h1><p>Q:LASSO减少特征的作用和PCA的降维作用类似吗？</p>
<p>A:不一样。LASSO的方法是直接减少特征数，做的是特征选择；PCA是通过空间转换将特征空间从高维空间转换到低维空间，是降维。</p>
<p>当你的特征有很强的语意的时候，PCA的缺点是丢失语意，此时用LASSO更好，如房产数据，这样做后续的分析会更高的保持可解释性；反之，对于你的数据，如果语意性不强，如图像数据，PCA更好。</p>
<p>Q:使用逻辑回归时怎么利用网格搜索来查找degree,c等超参数<br>A:<a href="https://coding.imooc.com/learn/questiondetail/61679.html" target="_blank" rel="noopener">https://coding.imooc.com/learn/questiondetail/61679.html</a></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fqjaoilapaj31kw0vn41c.jpg" alt></p>
<p>总的流程</p>
<ol>
<li>基本数据情况</li>
<li>检查数据无效值(NaN,NULL等)</li>
<li>绘图查看异常点</li>
<li>删除异常值</li>
<li>添加新特征</li>
<li>特征选择</li>
<li>特征缩放</li>
<li>应用算法+网格搜索</li>
</ol>
<h2 id="机器学习中的一些数学指标"><a href="#机器学习中的一些数学指标" class="headerlink" title="机器学习中的一些数学指标"></a>机器学习中的一些数学指标</h2><p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-v09-09-012650.png" alt></p>
<p>上述的三个数学指标其实本质上都是一样的</p>
<p><img src="https://blog-image-1257302654.cos.ap-guangzhou.myqcloud.com/2018-09-09-012941.png" alt></p>
<p>基于已有的数学概念进行抽象,得出范数的概念.其实是很简单的.对于右边的没有开根号是不影响最终结果的,有时候也可以叫做L2范数,因为开不开根号变化方向都是一致的,不影响最终结果</p>
<h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p><a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/" target="_blank" rel="noopener">sklearn 官方模型选择指导</a></p>
<p><a href="https://docs.microsoft.com/zh-cn/azure/machine-learning/studio/algorithm-cheat-sheet" target="_blank" rel="noopener">Microsoft Azure 官网模型推荐</a></p>
<h2 id="泰坦尼克存活预测"><a href="#泰坦尼克存活预测" class="headerlink" title="泰坦尼克存活预测"></a>泰坦尼克存活预测</h2><p><a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">Kaggle地址</a>]</p>
<p><a href="https://zhuanlan.zhihu.com/p/31743196" target="_blank" rel="noopener">参考地址,重点学习一下流程以及模型融合</a><br><a href="https://blog.csdn.net/han_xiaoyang/article/details/49797143" target="_blank" rel="noopener">参考地址2,寒小阳逻辑回归建模</a></p>
<h2 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h2><p><a href="https://zhuanlan.zhihu.com/p/26890738" target="_blank" rel="noopener">Kaggle机器学习之模型融合（stacking）心得</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/25836678" target="_blank" rel="noopener">模型融合方法概述</a></p>
<p><a href="https://jlunevermore.github.io/2016/06/25/14.Bagging%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="noopener">Bagging与随机森林,对西瓜书的一个总结</a></p>
<h2 id="udacity-总结挺好必看"><a href="#udacity-总结挺好必看" class="headerlink" title="udacity 总结挺好必看"></a>udacity 总结挺好必看</h2><p><a href="http://road2autodrive.info/" target="_blank" rel="noopener">偶像</a></p>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p><a href="https://mp.weixin.qq.com/s/3QFQRL708Muxf_QzKmSMlw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/3QFQRL708Muxf_QzKmSMlw</a></p>
<h2 id="牛人总结"><a href="#牛人总结" class="headerlink" title="牛人总结"></a>牛人总结</h2><p><a href="https://segmentfault.com/a/1190000012084849" target="_blank" rel="noopener">分享一波关于做Kaggle比赛，Jdata，天池的经验，看完我这篇就够了</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzI0NzE3NTAzOA%3D%3D&amp;mid=2652115209&amp;idx=2&amp;sn=003a5e0a8fdc4e4d9755b18031763796#wechat_redirect" target="_blank" rel="noopener">如何建立自己的应用型机器学习流程</a></p>
<h2 id="Kaggle-入门"><a href="#Kaggle-入门" class="headerlink" title="Kaggle 入门"></a>Kaggle 入门</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA%3D%3D&amp;mid=2650668868&amp;idx=3&amp;sn=ba389178ad651a78e35b3f16bb6ae560#wechat_redirect" target="_blank" rel="noopener">初学者应该参加哪些 Kaggle 比赛</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650670710&amp;idx=1&amp;sn=d75a077506c72eb5ba5d59c063cc0dda&amp;chksm=bec23b0589b5b213e1900c7f963d2e380e4df24726e070ac5f88d9b9e8b1f37bf06b32fe762b&amp;mpshare=1&amp;scene=1&amp;srcid=0409PduieO4ncwIVbg5YsaqW#rd" target="_blank" rel="noopener">Kaggle 六大比赛最全面解析</a></p>
<h2 id="好的视频资料"><a href="#好的视频资料" class="headerlink" title="好的视频资料"></a>好的视频资料</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650668953&amp;idx=1&amp;sn=68b70229dd96466ef0252ba672002f39&amp;chksm=bec1c2ea89b64bfce5e5a286041d5da8df44fc519b72e999ece90dc8d8b4e75d4862eb8a5a84&amp;mpshare=1&amp;scene=1&amp;srcid=1231OlnWXrdIR0QUx6a5bX2j#rd" target="_blank" rel="noopener">2017年度好视频</a></p>
<h2 id="深度学习机器学习常见工具包-cheatsheet"><a href="#深度学习机器学习常见工具包-cheatsheet" class="headerlink" title="深度学习机器学习常见工具包 cheatsheet"></a>深度学习机器学习常见工具包 cheatsheet</h2><p><a href="https://github.com/kailashahirwar/cheatsheets-ai" target="_blank" rel="noopener">https://github.com/kailashahirwar/cheatsheets-ai</a></p>
<h2 id="机器学习所需要的数学知识"><a href="#机器学习所需要的数学知识" class="headerlink" title="机器学习所需要的数学知识"></a>机器学习所需要的数学知识</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650670694&amp;idx=1&amp;sn=687dbfba5890cca3c082a1c373f04ba8&amp;chksm=bec23b1589b5b203a7b78d689b6469392a11133e9ae3558d71130cb75cf57dba1287c3de529d&amp;mpshare=1&amp;scene=1&amp;srcid=0409NwpiY3TIBsTdYowz87zC#rd" target="_blank" rel="noopener">一文读懂机器学习需要哪些数学知识</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&amp;mid=2650670670&amp;idx=1&amp;sn=8b3c114e542843a81599dcf6c8441e8d&amp;chksm=bec23b3d89b5b22bc37d6202a0276cd7824b38a617c1f1deab0d70d63b35ec48db735124b2b4&amp;mpshare=1&amp;scene=1&amp;srcid=0409cR4X0hRgCTEqKh383YaN#rd" target="_blank" rel="noopener">机器学习数学知识</a></p>
<h2 id="Google-发布关于机器学习工程的最佳实践"><a href="#Google-发布关于机器学习工程的最佳实践" class="headerlink" title="Google 发布关于机器学习工程的最佳实践"></a>Google 发布关于机器学习工程的最佳实践</h2><p><a href="https://mp.weixin.qq.com/s/Jh-55wfvY6DByniDK2MIRQ" target="_blank" rel="noopener">点我查看 google 的最佳实践</a></p>
<h2 id="如何通过网格搜索来寻找自定义的Pipeline模型-比如自定义的多项式线性模型"><a href="#如何通过网格搜索来寻找自定义的Pipeline模型-比如自定义的多项式线性模型" class="headerlink" title="如何通过网格搜索来寻找自定义的Pipeline模型(比如自定义的多项式线性模型)"></a>如何通过网格搜索来寻找自定义的Pipeline模型(比如自定义的多项式线性模型)</h2><p><a href="https://coding.imooc.com/learn/questiondetail/61679.html" target="_blank" rel="noopener">https://coding.imooc.com/learn/questiondetail/61679.html</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/数据分析/" rel="tag"># 数据分析</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/22/深度学习备注/" rel="next" title="深度学习备注">
                <i class="fa fa-chevron-left"></i> 深度学习备注
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/12/14/读芒格《人类误判心理学》/" rel="prev" title="读芒格《人类误判心理学》">
                读芒格《人类误判心理学》 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/avatar.jpeg" alt="张俊">
          <p class="site-author-name" itemprop="name">张俊</p>
           
              <p class="site-description motion-element" itemprop="description">过一种有价值的中产阶级生活</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">82</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ZJsnowman" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/zjsnowman" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                    
                      Twitter
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/ZJsnowman/activities" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-quora"></i>
                  
                    
                      知乎
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Naive-Bayes-贝叶斯推断"><span class="nav-number">1.</span> <span class="nav-text">Naive Bayes(贝叶斯推断)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#朴素贝叶斯为啥朴素"><span class="nav-number">1.1.</span> <span class="nav-text">朴素贝叶斯为啥朴素</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#朴素贝叶斯的优势和劣势"><span class="nav-number">1.2.</span> <span class="nav-text">朴素贝叶斯的优势和劣势</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SVM-支持向量机"><span class="nav-number">2.</span> <span class="nav-text">SVM(支持向量机)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Decision-Trees-决策树"><span class="nav-number">3.</span> <span class="nav-text">Decision Trees (决策树)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#信息熵"><span class="nav-number">3.1.</span> <span class="nav-text">信息熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基尼系数"><span class="nav-number">3.2.</span> <span class="nav-text">基尼系数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#信息增益"><span class="nav-number">3.3.</span> <span class="nav-text">信息增益</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优缺点"><span class="nav-number">3.4.</span> <span class="nav-text">优缺点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#k-nearest-neighbors"><span class="nav-number">4.</span> <span class="nav-text">k-nearest neighbors</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#集成学习"><span class="nav-number">5.</span> <span class="nav-text">集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Bagging-and-随机森林"><span class="nav-number">5.1.</span> <span class="nav-text">Bagging and 随机森林</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ada-Boosting"><span class="nav-number">5.2.</span> <span class="nav-text">Ada Boosting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient-Boosting"><span class="nav-number">5.3.</span> <span class="nav-text">Gradient Boosting</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#准确度与训练集大小的关系"><span class="nav-number">6.</span> <span class="nav-text">准确度与训练集大小的关系</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据类型"><span class="nav-number">7.</span> <span class="nav-text">数据类型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#判断离散还是连续"><span class="nav-number">8.</span> <span class="nav-text">判断离散还是连续</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#回归-regression"><span class="nav-number">9.</span> <span class="nav-text">回归(regression)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#最小二乘法"><span class="nav-number">9.1.</span> <span class="nav-text">最小二乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性回归"><span class="nav-number">9.2.</span> <span class="nav-text">线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性回归误差"><span class="nav-number">9.2.1.</span> <span class="nav-text">线性回归误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#误差平法和"><span class="nav-number">9.2.2.</span> <span class="nav-text">误差平法和</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#最小化误差平方和的算法"><span class="nav-number">9.2.2.1.</span> <span class="nav-text">最小化误差平方和的算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#问题"><span class="nav-number">9.2.2.2.</span> <span class="nav-text">问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决定系数-R-suqre"><span class="nav-number">9.3.</span> <span class="nav-text">决定系数 R suqre</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监督分类和回归的区别"><span class="nav-number">9.4.</span> <span class="nav-text">监督分类和回归的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多元线性回归-多变量回归-元理解成变量即可"><span class="nav-number">9.5.</span> <span class="nav-text">多元线性回归(多变量回归,元理解成变量即可)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多项式回归"><span class="nav-number">9.6.</span> <span class="nav-text">多项式回归</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#异常值"><span class="nav-number">10.</span> <span class="nav-text">异常值</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#原因"><span class="nav-number">10.1.</span> <span class="nav-text">原因</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#去除异常值的算法"><span class="nav-number">10.2.</span> <span class="nav-text">去除异常值的算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Clustering-聚类"><span class="nav-number">11.</span> <span class="nav-text">Clustering(聚类)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#K-means"><span class="nav-number">11.1.</span> <span class="nav-text">K-means</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#K-means的局限"><span class="nav-number">11.2.</span> <span class="nav-text">K-means的局限</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征缩放"><span class="nav-number">12.</span> <span class="nav-text">特征缩放</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#受此影响的机器学习算法"><span class="nav-number">12.1.</span> <span class="nav-text">受此影响的机器学习算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#涉及的一些中英对照"><span class="nav-number">13.</span> <span class="nav-text">涉及的一些中英对照</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#文本"><span class="nav-number">14.</span> <span class="nav-text">文本</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征选择"><span class="nav-number">15.</span> <span class="nav-text">特征选择</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化"><span class="nav-number">15.1.</span> <span class="nav-text">正则化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#一些其他的点"><span class="nav-number">16.</span> <span class="nav-text">一些其他的点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PCA"><span class="nav-number">17.</span> <span class="nav-text">PCA</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#帮助理解PCA"><span class="nav-number">17.1.</span> <span class="nav-text">帮助理解PCA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PCA的功能"><span class="nav-number">17.2.</span> <span class="nav-text">PCA的功能</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#交叉验证"><span class="nav-number">18.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#方差偏差均衡"><span class="nav-number">19.</span> <span class="nav-text">方差偏差均衡</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#如何解决过拟合问题"><span class="nav-number">20.</span> <span class="nav-text">如何解决过拟合问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Q-amp-A"><span class="nav-number">21.</span> <span class="nav-text">Q&amp;A</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-number">22.</span> <span class="nav-text">总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习中的一些数学指标"><span class="nav-number">22.1.</span> <span class="nav-text">机器学习中的一些数学指标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型选择"><span class="nav-number">22.2.</span> <span class="nav-text">模型选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#泰坦尼克存活预测"><span class="nav-number">22.3.</span> <span class="nav-text">泰坦尼克存活预测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型融合"><span class="nav-number">22.4.</span> <span class="nav-text">模型融合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#udacity-总结挺好必看"><span class="nav-number">22.5.</span> <span class="nav-text">udacity 总结挺好必看</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS"><span class="nav-number">22.6.</span> <span class="nav-text">HDFS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#牛人总结"><span class="nav-number">22.7.</span> <span class="nav-text">牛人总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kaggle-入门"><span class="nav-number">22.8.</span> <span class="nav-text">Kaggle 入门</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#好的视频资料"><span class="nav-number">22.9.</span> <span class="nav-text">好的视频资料</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习机器学习常见工具包-cheatsheet"><span class="nav-number">22.10.</span> <span class="nav-text">深度学习机器学习常见工具包 cheatsheet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习所需要的数学知识"><span class="nav-number">22.11.</span> <span class="nav-text">机器学习所需要的数学知识</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Google-发布关于机器学习工程的最佳实践"><span class="nav-number">22.12.</span> <span class="nav-text">Google 发布关于机器学习工程的最佳实践</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#如何通过网格搜索来寻找自定义的Pipeline模型-比如自定义的多项式线性模型"><span class="nav-number">22.13.</span> <span class="nav-text">如何通过网格搜索来寻找自定义的Pipeline模型(比如自定义的多项式线性模型)</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张俊</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  

    
      <script id="dsq-count-scr" src="https://ZJsnowman.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://zjsnowman.com/2018/11/27/机器学习备注/';
          this.page.identifier = '2018/11/27/机器学习备注/';
          this.page.title = '机器学习';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://ZJsnowman.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  








  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.2"></script>



  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("1m1SVHmQhKszN3lTe3rKgo87-gzGzoHsz", "i9e5m0oHfrGz1EzsarxpYbh2");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
